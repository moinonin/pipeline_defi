{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas import DataFrame\n",
    "import pickle, random\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import KDTree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df0 = pd.read_csv('../spreadsheets/rlhf_1064.csv') # 0.005, 0.75, 0.1, 0.95, 0.999, 12000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_159nlp.csv') # second Best 0.01, 0.85, 0.01, 0.95, 0.95, 12000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_07rl.csv') # Best\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_1072.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/shufled_rlhf_11rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_12rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_15rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_154nlp_balanced.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_19rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_24rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_23rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_25rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_26rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_157nlp.csv') # 0.7, 0.95, 0.5, 0.999, 0.99, 16000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_157nlpgate.csv') # 0.25, 0.95, 0.01, 0.997, 0.999, 14000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_29rl.csv') # 0.9, 0.9, 0.005, 0.95, 0.999, 10000,\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_30rl.csv') # 0.005, 0.75, 0.1, 0.95, 0.999, 12000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_32rl.csv') # 0.01, 0.85, 0.01, 0.95, 0.95, 12000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_33rl.csv')# 0.05, 0.85, 0.01, 0.997, 0.95, 4000\n",
    "# df0 = pd.read_csv('../spreadsheets/rlhf_small_36rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_39rl.csv')# 0.05, 0.85, 0.01, 0.997, 0.95, 4000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_154nlp_refined.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_27rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_small_43rl.csv') # 0.001, 0.99, 1.0, 0.95, 0.99, 10000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_1064_2.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_154nlp_refined.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_46rl_balanced.csv')\n",
    "df0 = pd.read_csv('../spreadsheets/rlhf_large_99rl_refined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'ema-26', 'ema-12', 'low', 'mean-grad-hist', 'close',\n",
       "       'volume', 'sma-05', 'sma-07', 'sma-25', 'long_jcrosk', 'short_kdj',\n",
       "       'sma-compare', 'ask', 'bid', 'is_short', 'nlpreds', 'action',\n",
       "       'predicted_action', 'reward', 'refined-action'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df0['action'] = df0['action'].replace('go_long', 'do_nothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>ema-26</th>\n",
       "      <th>ema-12</th>\n",
       "      <th>low</th>\n",
       "      <th>mean-grad-hist</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sma-05</th>\n",
       "      <th>sma-07</th>\n",
       "      <th>...</th>\n",
       "      <th>short_kdj</th>\n",
       "      <th>sma-compare</th>\n",
       "      <th>ask</th>\n",
       "      <th>bid</th>\n",
       "      <th>is_short</th>\n",
       "      <th>nlpreds</th>\n",
       "      <th>action</th>\n",
       "      <th>predicted_action</th>\n",
       "      <th>reward</th>\n",
       "      <th>refined-action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.970000</td>\n",
       "      <td>145.250000</td>\n",
       "      <td>136.447866</td>\n",
       "      <td>134.617469</td>\n",
       "      <td>138.440000</td>\n",
       "      <td>0</td>\n",
       "      <td>141.770000</td>\n",
       "      <td>4.958630e+03</td>\n",
       "      <td>137.642000</td>\n",
       "      <td>137.210000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.504043e+03</td>\n",
       "      <td>2.454587e+03</td>\n",
       "      <td>0</td>\n",
       "      <td>do_nothing</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_long</td>\n",
       "      <td>7.113071</td>\n",
       "      <td>go_short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.011891</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>0.011135</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>2.062242e+08</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>0.012307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.016121e+08</td>\n",
       "      <td>1.046121e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>do_nothing</td>\n",
       "      <td>do_nothing</td>\n",
       "      <td>go_long</td>\n",
       "      <td>-35.788772</td>\n",
       "      <td>do_nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.089250</td>\n",
       "      <td>0.089320</td>\n",
       "      <td>0.089056</td>\n",
       "      <td>0.088819</td>\n",
       "      <td>0.089250</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089260</td>\n",
       "      <td>2.076000e+03</td>\n",
       "      <td>0.089262</td>\n",
       "      <td>0.089227</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.038058e+03</td>\n",
       "      <td>1.037942e+03</td>\n",
       "      <td>0</td>\n",
       "      <td>do_nothing</td>\n",
       "      <td>go_long</td>\n",
       "      <td>go_long</td>\n",
       "      <td>30.299614</td>\n",
       "      <td>go_long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.150210</td>\n",
       "      <td>0.147727</td>\n",
       "      <td>0.143828</td>\n",
       "      <td>0.147030</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>6.329608e+06</td>\n",
       "      <td>0.150122</td>\n",
       "      <td>0.150167</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.185970e+06</td>\n",
       "      <td>3.143638e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>do_nothing</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_short</td>\n",
       "      <td>64.003147</td>\n",
       "      <td>go_short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.385000</td>\n",
       "      <td>50.595000</td>\n",
       "      <td>49.302116</td>\n",
       "      <td>48.528804</td>\n",
       "      <td>49.325000</td>\n",
       "      <td>0</td>\n",
       "      <td>50.375000</td>\n",
       "      <td>6.648470e+03</td>\n",
       "      <td>49.787000</td>\n",
       "      <td>49.646429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.357224e+03</td>\n",
       "      <td>3.291246e+03</td>\n",
       "      <td>1</td>\n",
       "      <td>do_nothing</td>\n",
       "      <td>do_nothing</td>\n",
       "      <td>go_long</td>\n",
       "      <td>-7.181780</td>\n",
       "      <td>do_nothing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         open        high      ema-26      ema-12         low  mean-grad-hist  \\\n",
       "0  138.970000  145.250000  136.447866  134.617469  138.440000               0   \n",
       "1    0.011821    0.011891    0.012238    0.012116    0.011135               1   \n",
       "2    0.089250    0.089320    0.089056    0.088819    0.089250               1   \n",
       "3    0.147040    0.150210    0.147727    0.143828    0.147030               0   \n",
       "4   49.385000   50.595000   49.302116   48.528804   49.325000               0   \n",
       "\n",
       "        close        volume      sma-05      sma-07  ...  short_kdj  \\\n",
       "0  141.770000  4.958630e+03  137.642000  137.210000  ...          0   \n",
       "1    0.011482  2.062242e+08    0.012085    0.012307  ...          0   \n",
       "2    0.089260  2.076000e+03    0.089262    0.089227  ...          0   \n",
       "3    0.149020  6.329608e+06    0.150122    0.150167  ...          0   \n",
       "4   50.375000  6.648470e+03   49.787000   49.646429  ...          0   \n",
       "\n",
       "   sma-compare           ask           bid  is_short     nlpreds      action  \\\n",
       "0            0  2.504043e+03  2.454587e+03         0  do_nothing    go_short   \n",
       "1            0  1.016121e+08  1.046121e+08         0  do_nothing  do_nothing   \n",
       "2            0  1.038058e+03  1.037942e+03         0  do_nothing     go_long   \n",
       "3            0  3.185970e+06  3.143638e+06         1  do_nothing    go_short   \n",
       "4            0  3.357224e+03  3.291246e+03         1  do_nothing  do_nothing   \n",
       "\n",
       "  predicted_action     reward refined-action  \n",
       "0          go_long   7.113071       go_short  \n",
       "1          go_long -35.788772     do_nothing  \n",
       "2          go_long  30.299614        go_long  \n",
       "3         go_short  64.003147       go_short  \n",
       "4          go_long  -7.181780     do_nothing  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df0['nlpreds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df0['refined-action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nlpreds\n",
       "do_nothing    398\n",
       "go_short      136\n",
       "go_long        98\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['nlpreds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df: DataFrame) -> DataFrame:\n",
    "    train_data = pd.DataFrame()\n",
    "    for col in df.columns:\n",
    "        col_name = col.split(' ')[0]\n",
    "        train_data[f'{col_name}'] = df[col]\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf0 = pd.DataFrame()\n",
    "train_data = prep_data(df0) if newdf0.empty else prep_data(newdf0)\n",
    "#train_data = prep_data(newdf0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>ema-26</th>\n",
       "      <th>ema-12</th>\n",
       "      <th>low</th>\n",
       "      <th>mean-grad-hist</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sma-05</th>\n",
       "      <th>sma-07</th>\n",
       "      <th>...</th>\n",
       "      <th>short_kdj</th>\n",
       "      <th>sma-compare</th>\n",
       "      <th>ask</th>\n",
       "      <th>bid</th>\n",
       "      <th>is_short</th>\n",
       "      <th>nlpreds</th>\n",
       "      <th>action</th>\n",
       "      <th>predicted_action</th>\n",
       "      <th>reward</th>\n",
       "      <th>refined-action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.970000</td>\n",
       "      <td>145.250000</td>\n",
       "      <td>136.447866</td>\n",
       "      <td>134.617469</td>\n",
       "      <td>138.440000</td>\n",
       "      <td>0</td>\n",
       "      <td>141.770000</td>\n",
       "      <td>4.958630e+03</td>\n",
       "      <td>137.642000</td>\n",
       "      <td>137.210000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.504043e+03</td>\n",
       "      <td>2.454587e+03</td>\n",
       "      <td>0</td>\n",
       "      <td>do_nothing</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_long</td>\n",
       "      <td>7.113071</td>\n",
       "      <td>go_short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.011891</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>0.011135</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>2.062242e+08</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>0.012307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.016121e+08</td>\n",
       "      <td>1.046121e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>do_nothing</td>\n",
       "      <td>do_nothing</td>\n",
       "      <td>go_long</td>\n",
       "      <td>-35.788772</td>\n",
       "      <td>do_nothing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         open        high      ema-26      ema-12         low  mean-grad-hist  \\\n",
       "0  138.970000  145.250000  136.447866  134.617469  138.440000               0   \n",
       "1    0.011821    0.011891    0.012238    0.012116    0.011135               1   \n",
       "\n",
       "        close        volume      sma-05      sma-07  ...  short_kdj  \\\n",
       "0  141.770000  4.958630e+03  137.642000  137.210000  ...          0   \n",
       "1    0.011482  2.062242e+08    0.012085    0.012307  ...          0   \n",
       "\n",
       "   sma-compare           ask           bid  is_short     nlpreds      action  \\\n",
       "0            0  2.504043e+03  2.454587e+03         0  do_nothing    go_short   \n",
       "1            0  1.016121e+08  1.046121e+08         0  do_nothing  do_nothing   \n",
       "\n",
       "  predicted_action     reward refined-action  \n",
       "0          go_long   7.113071       go_short  \n",
       "1          go_long -35.788772     do_nothing  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode actions into numerical values\n",
    "action_mapping = {\"go_long\": 0, \"go_short\": 1, \"do_nothing\": 2}\n",
    "action_col = 'predicted_action' #if newdf0.empty else 'refined-action'\n",
    "train_data[\"action_num\"] = train_data[f\"{action_col}\"].map(action_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'ema-26', 'ema-12', 'low', 'mean-grad-hist', 'close',\n",
       "       'volume', 'sma-05', 'sma-07', 'sma-25', 'long_jcrosk', 'short_kdj',\n",
       "       'sma-compare', 'ask', 'bid', 'is_short', 'nlpreds', 'action',\n",
       "       'predicted_action', 'reward', 'refined-action', 'action_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RL parameters\n",
    "states = train_data[[\"sma-05\", \"sma-07\", \"sma-25\", \"sma-compare\", \"is_short\"]].values  # Include binary_state\n",
    "actions = list(action_mapping.values())  # Action space\n",
    "rewards = train_data[\"reward\"].values  # Rewards\n",
    "n_states = states.shape[0]\n",
    "n_actions = len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Q-table\n",
    "q_table = np.zeros((n_states, n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25, 0.95, 1.0, 0.99, 0.99, 10000]\n"
     ]
    }
   ],
   "source": [
    "list_1 = [\n",
    "    [0.25, 0.95, 1.0, 0.99, 0.99, 10000],\n",
    "]\n",
    "\n",
    "list_2 = [\n",
    "    [0.25, 0.95, 1.0, 0.99, 0.99, 10000],\n",
    "]\n",
    "\n",
    "# Combine the lists and remove duplicates\n",
    "combined_set = {tuple(sublist) for sublist in list_1 + list_2}\n",
    "\n",
    "# Convert the set back to a list of lists\n",
    "combined_list = [list(sublist) for sublist in combined_set]\n",
    "\n",
    "# Print the combined list\n",
    "for sublist in combined_list:\n",
    "    print(sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyperparameters = [\n",
    "    [0.005,0.85,0.99,0.99,0.997,6000],\n",
    "    [0.001, 0.99, 1.0, 0.95, 0.99, 10000],\n",
    "    [1, 0.9, 1.0, 0.99, 0.99, 11000],\n",
    "    [0.1, 0.9, 0.1, 0.99, 0.995, 4000],\n",
    "    [0.005, 0.75, 0.1, 0.95, 0.999, 12000],\n",
    "    [0.001, 0.75, 1.0, 0.99, 0.99, 30000],\n",
    "    [1, 0.75, 0.005, 0.95, 0.95, 22000],\n",
    "    [0.01, 0.99, 1.0, 0.95, 0.99, 16000],\n",
    "    [0.7, 0.99, 1.0, 0.95, 0.997, 8000],\n",
    "    [0.01, 0.95, 1.0, 0.997, 0.995, 26000],\n",
    "    [0.25, 0.95, 0.01, 0.997, 0.999, 14000],\n",
    "    [0.5, 0.85, 0.5, 0.997, 0.997, 14000],\n",
    "    [0.01, 0.85, 0.01, 0.95, 0.95, 12000],\n",
    "    [0.9, 0.99, 0.5, 0.995, 0.95, 12000],\n",
    "    [0.05, 0.9, 0.5, 0.95, 0.999, 4000],\n",
    "    [0.05, 0.99, 0.5, 0.99, 0.997, 6000],\n",
    "    [1, 0.75, 0.05, 0.999, 0.999, 10000],\n",
    "    [0.9, 0.95, 1.0, 0.99, 0.99, 8000],\n",
    "    [0.25, 0.75, 0.01, 0.995, 0.999, 20000],\n",
    "    [0.3, 0.75, 1.0, 0.995, 0.99, 10000],\n",
    "    [1, 0.9, 1.0, 0.999, 0.999, 10000],\n",
    "    [0.7, 0.75, 1.0, 0.97, 0.999, 28000],\n",
    "    [0.05, 0.95, 1.0, 0.999, 0.995, 12000],\n",
    "    [0.7, 0.95, 0.5, 0.999, 0.99, 16000],\n",
    "    [0.25, 0.95, 1.0, 0.99, 0.99, 10000],\n",
    "    [0.25, 0.99, 0.01, 0.997, 0.99, 8000],\n",
    "    [1, 0.95, 0.1, 0.96, 0.96, 12000],\n",
    "    [0.9, 0.9, 0.005, 0.95, 0.999, 10000],\n",
    "    [0.05, 0.85, 0.01, 0.997, 0.95, 4000],\n",
    "    [0.01, 0.9, 0.5, 0.999, 0.999, 1500],\n",
    "    [1, 0.85, 1.0, 0.95, 0.997, 21000],\n",
    "    [0.7, 0.9, 0.05, 0.95, 0.95, 20000]\n",
    "\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [0.005, 0.85, 0.99, 0.99, 0.997, 6000])\n",
      "(1, [0.001, 0.99, 1.0, 0.95, 0.99, 10000])\n",
      "(2, [1, 0.9, 1.0, 0.99, 0.99, 11000])\n",
      "(3, [0.1, 0.9, 0.1, 0.99, 0.995, 4000])\n",
      "(4, [0.005, 0.75, 0.1, 0.95, 0.999, 12000])\n",
      "(5, [0.001, 0.75, 1.0, 0.99, 0.99, 30000])\n",
      "(6, [1, 0.75, 0.005, 0.95, 0.95, 22000])\n",
      "(7, [0.01, 0.99, 1.0, 0.95, 0.99, 16000])\n",
      "(8, [0.7, 0.99, 1.0, 0.95, 0.997, 8000])\n",
      "(9, [0.01, 0.95, 1.0, 0.997, 0.995, 26000])\n",
      "(10, [0.25, 0.95, 0.01, 0.997, 0.999, 14000])\n",
      "(11, [0.5, 0.85, 0.5, 0.997, 0.997, 14000])\n",
      "(12, [0.01, 0.85, 0.01, 0.95, 0.95, 12000])\n",
      "(13, [0.9, 0.99, 0.5, 0.995, 0.95, 12000])\n",
      "(14, [0.05, 0.9, 0.5, 0.95, 0.999, 4000])\n",
      "(15, [0.05, 0.99, 0.5, 0.99, 0.997, 6000])\n",
      "(16, [1, 0.75, 0.05, 0.999, 0.999, 10000])\n",
      "(17, [0.9, 0.95, 1.0, 0.99, 0.99, 8000])\n",
      "(18, [0.25, 0.75, 0.01, 0.995, 0.999, 20000])\n",
      "(19, [0.3, 0.75, 1.0, 0.995, 0.99, 10000])\n",
      "(20, [1, 0.9, 1.0, 0.999, 0.999, 10000])\n",
      "(21, [0.7, 0.75, 1.0, 0.97, 0.999, 28000])\n",
      "(22, [0.05, 0.95, 1.0, 0.999, 0.995, 12000])\n",
      "(23, [0.7, 0.95, 0.5, 0.999, 0.99, 16000])\n",
      "(24, [0.25, 0.95, 1.0, 0.99, 0.99, 10000])\n",
      "(25, [0.25, 0.99, 0.01, 0.997, 0.99, 8000])\n",
      "(26, [1, 0.95, 0.1, 0.96, 0.96, 12000])\n",
      "(27, [0.9, 0.9, 0.005, 0.95, 0.999, 10000])\n",
      "(28, [0.05, 0.85, 0.01, 0.997, 0.95, 4000])\n",
      "(29, [0.01, 0.9, 0.5, 0.999, 0.999, 1500])\n",
      "(30, [1, 0.85, 1.0, 0.95, 0.997, 21000])\n",
      "(31, [0.7, 0.9, 0.05, 0.95, 0.95, 20000])\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(Hyperparameters):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.3, 0.75, 1.0, 0.995, 0.99, 10000\n",
    "'''\n",
    "alpha = 0.7\n",
    "gamma = 0.75\n",
    "epsilon = 1.0\n",
    "min_epsilon = 0.97\n",
    "decay_rate = 0.97\n",
    "n_episodes = 28000\n",
    "n_states = states.shape[0]  # Number of states\n",
    "n_actions = len(actions)  # Number of actions\n",
    "'''\n",
    "alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes = Hyperparameters[3] # Hyperparameters[30] # Hyperparameters[22] #Hyperparameters[9] # Hyperparameters[21]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_index_mapping(df):\n",
    "    state_to_index = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        state = (row['sma-05'], row['sma-07'], row['sma-25'], row['sma-compare'], row['is_short'])\n",
    "        state_to_index[state] = idx\n",
    "    return state_to_index\n",
    "\n",
    "# Assuming 'df' is your dataframe used during training\n",
    "state_to_index = create_state_index_mapping(train_data)\n",
    "\n",
    "# Save the state_to_index dictionary for later use\n",
    "np.save('small_state_to_index.npy', state_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper function to choose an action using epsilon-greedy\n",
    "def choose_action(state, epsilon):\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        return np.random.randint(0, n_actions)  # Explore: random action\n",
    "    else:\n",
    "        return np.argmax(q_table[state])  # Exploit: best known action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Load the best episode transitions\n",
    "best_episode_transitions = np.load(\"best_small_episode_transitions.npy\", allow_pickle=True)\n",
    "\n",
    "# Optionally, pre-train the Q-table using the best episode\n",
    "for state, action, reward, next_state in best_episode_transitions:\n",
    "    best_next_action = np.argmax(q_table[next_state])\n",
    "    q_table[state, action] += alpha * (reward + gamma * q_table[next_state, best_next_action] - q_table[state, action])\n",
    "\n",
    "# Load the previously saved Q-table and best episode transitions\n",
    "best_q_table = np.load(\"best_small_q_table.npy\")  # Load the best Q-table\n",
    "best_episode_transitions = np.load(\"best_small_episode_transitions.npy\", allow_pickle=True).tolist()  # Load best transitions'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating results per episode...:   0%|          | 0/4000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 338 is out of bounds for axis 0 with size 338",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[819], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m reward \u001b[38;5;241m=\u001b[39m rewards[next_state]\n\u001b[1;32m     24\u001b[0m best_next_action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(q_table[next_state])\n\u001b[0;32m---> 25\u001b[0m best_q_table[current_state, action] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m (\n\u001b[1;32m     26\u001b[0m     reward \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m q_table[next_state, best_next_action] \u001b[38;5;241m-\u001b[39m q_table[current_state, action]\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward  \u001b[38;5;66;03m# Accumulate reward\u001b[39;00m\n\u001b[1;32m     30\u001b[0m episode_transitions\u001b[38;5;241m.\u001b[39mappend((current_state, action, reward, next_state))\n",
      "\u001b[0;31mIndexError\u001b[0m: index 338 is out of bounds for axis 0 with size 338"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Define hyperparameters\n",
    "\n",
    "# Initialize lists to store rewards and transitions per episode\n",
    "rewards_per_episode = []\n",
    "best_episode_transitions = []\n",
    "best_q_table = None\n",
    "best_total_reward = float('-inf')  # Initialize with negative infinity\n",
    "best_hyperparameters = {}  # Dictionary to store hyperparameters of best episode\n",
    "\n",
    "for episode in tqdm(range(n_episodes), desc=\"Evaluating results per episode...\"):\n",
    "    current_state = np.random.randint(0, n_states)  # Random initial state\n",
    "    total_reward = 0  # Initialize total reward for the current episode\n",
    "    episode_transitions = []  # Store (state, action, reward, next_state) tuples for this episode\n",
    "\n",
    "    while current_state < n_states - 1:\n",
    "        action = choose_action(current_state, epsilon)\n",
    "        next_state = current_state + 1  # This depends on your environment logic\n",
    "        reward = rewards[next_state]\n",
    "\n",
    "        best_next_action = np.argmax(q_table[next_state])\n",
    "        q_table[current_state, action] += alpha * (\n",
    "            reward + gamma * q_table[next_state, best_next_action] - q_table[current_state, action]\n",
    "        )\n",
    "\n",
    "        total_reward += reward  # Accumulate reward\n",
    "        episode_transitions.append((current_state, action, reward, next_state))\n",
    "        current_state = next_state  # Move to next state\n",
    "\n",
    "    rewards_per_episode.append(total_reward)  # Store total reward for the current episode\n",
    "\n",
    "    # Check if this is the best episode so far\n",
    "    if total_reward > best_total_reward:\n",
    "        best_total_reward = total_reward\n",
    "        best_episode_transitions = episode_transitions.copy()\n",
    "        best_q_table = q_table.copy()\n",
    "\n",
    "        # Store the hyperparameters at the best episode\n",
    "        best_hyperparameters = {\n",
    "            \"alpha\": alpha,\n",
    "            \"gamma\": gamma,\n",
    "            \"epsilon\": epsilon,\n",
    "            \"min_epsilon\": min_epsilon,\n",
    "            \"decay_rate\": decay_rate,\n",
    "            \"n_episodes\": n_episodes\n",
    "        }\n",
    "\n",
    "    # Decay epsilon\n",
    "    epsilon = max(min_epsilon, epsilon * decay_rate)\n",
    "\n",
    "    # Optional: Log progress\n",
    "    if episode % 400 == 0:  \n",
    "        print(f\"Episode {episode}/{n_episodes} - Total Reward: {total_reward}, Epsilon: {epsilon}\")\n",
    "\n",
    "# Save the best episode's Q-table\n",
    "np.save(\"best_small_q_table.npy\", best_q_table)\n",
    "# Save the best episode's transitions\n",
    "np.save(\"best_small_episode_transitions.npy\", np.array(best_episode_transitions, dtype=object))\n",
    "# Plot the rewards per episode\n",
    "plt.plot(rewards_per_episode)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Rewards per Episode')\n",
    "plt.show()\n",
    "\n",
    "# Print best episode results\n",
    "print(f\"Best Episode Reward: {best_total_reward}\")\n",
    "print(f\"Best Episode Transitions: {best_episode_transitions[:5]} ...\")  # Show first 5 transitions\n",
    "print(f\"Best Episode Hyperparameters: {best_hyperparameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_q_table(file_path):\n",
    "    return np.load(file_path)\n",
    "\n",
    "def load_state_index_mapping(file_path):\n",
    "    return np.load(file_path, allow_pickle=True).item()\n",
    "\n",
    "loaded_mapping = load_state_index_mapping(file_path=\"small_state_to_index.npy\")\n",
    "loaded_qtable = load_q_table(file_path=\"small_q_table.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_state(sma_05: float, sma_07: float, sma_25: float, sma_compare: int, is_short: int):\n",
    "    state = np.array([[sma_05, sma_07, sma_25, sma_compare, is_short]])\n",
    "    if not np.all(np.isfinite(state)):\n",
    "        state = np.nan_to_num(state, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_action(state, q_table, state_to_index, action_mapping, default_action: str = None):\n",
    "    state_tuple = tuple(state.flatten())\n",
    "\n",
    "    state_index = state_to_index.get(state_tuple, -1)\n",
    "\n",
    "    if not state_index == -1:\n",
    "        try:\n",
    "            q_values = q_table[state_index]\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            #return default_action\n",
    "    else:\n",
    "        state_tuples = list(state_to_index.keys())\n",
    "        kdtree = KDTree(state_tuples)\n",
    "        distance, index = kdtree.query(state.flatten())\n",
    "        nearest_state_tuple = state_tuples[index]\n",
    "        new_state_index = state_to_index[nearest_state_tuple]\n",
    "        q_values = loaded_qtable[new_state_index]\n",
    "    \n",
    "    #q_values = q_table[state_index]\n",
    "    best_action_index = np.argmax(q_values)\n",
    "    action = [action for action, index in action_mapping.items() if index == best_action_index][0]\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "with open(\"small_q_table.npy\", \"rb\") as f:\n",
    "    q_table = load_q_table(\"small_q_table.npy\")\n",
    "\n",
    "with open(\"small_state_to_index.npy\", \"rb\") as f:\n",
    "    state_to_index = load_state_index_mapping(\"small_state_to_index.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[[\"sma-05\", \"sma-07\", \"sma-25\", \"sma-compare\", \"is_short\"]].values\n",
    "state_1 = list(X[-1:].flatten()) # sample: [[0.87024    0.85277143 0.779504   0.         1.        ]]\n",
    "\n",
    "state = prep_state(*state_1)\n",
    "action_mapping = {\"go_long\": 0, \"go_short\": 1, \"do_nothing\": 2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted action for the state is: do_nothing\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    predicted_action = predict_action(state, q_table, state_to_index, action_mapping)\n",
    "    print(f\"The predicted action for the state is: {predicted_action}\")\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    print(\"The state is not found in the state index mapping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict an entire range\n",
    "for idx, row in train_data.iterrows():\n",
    "    state = row[[\"sma-05\", \"sma-07\", \"sma-25\", \"sma-compare\", \"is_short\"]].values\n",
    "    action = predict_action(state, q_table, state_to_index, action_mapping)\n",
    "    train_data.loc[idx, \"predicted_action\"] = action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (train_data['predicted_action'].nunique() < 2):\n",
    "    raise ValueError(\"Model predictions are invalid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_action\n",
       "go_long       145\n",
       "go_short      112\n",
       "do_nothing     81\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['predicted_action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = train_data[(train_data['nlpreds'] == 'go_long') & (train_data['reward'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_short\n",
       "0    46\n",
       "1    33\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m['is_short'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nlpreds\n",
       "go_short      136\n",
       "do_nothing    123\n",
       "go_long        79\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df0[(df0['reward'] > 0)]\n",
    "s['nlpreds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed state 0/337\n",
      "Current Predicted Reward: 30.2996141\n",
      "Current Actual Reward: 30.2996141\n",
      "Processed state 100/337\n",
      "Current Predicted Reward: 719.1028729300001\n",
      "Current Actual Reward: 2168.376925440001\n",
      "Processed state 200/337\n",
      "Current Predicted Reward: 1635.58436301\n",
      "Current Actual Reward: 5261.63269588\n",
      "Processed state 300/337\n",
      "Current Predicted Reward: 5219.13474169\n",
      "Current Actual Reward: 12579.267152869998\n",
      "Cumulative Predicted Reward: 5776.222654539998\n",
      "Cumulative Actual Reward: 14610.103779070001\n",
      "Prediction Efficiency: -60.46%\n"
     ]
    }
   ],
   "source": [
    "# Performance measures\n",
    "# Initialize cumulative rewards\n",
    "cumulative_predicted_reward = 0\n",
    "cumulative_actual_reward = 0\n",
    "\n",
    "# Iterate through states to calculate rewards\n",
    "for state_index in range(n_states - 1):\n",
    "    # Predicted action from Q-table\n",
    "    predicted_action = np.argmax(q_table[state_index])  # Best action for the current state\n",
    "    # Actual action from the ground truth\n",
    "    actual_action = train_data[\"action_num\"].iloc[state_index]\n",
    "\n",
    "    # Get reward for predicted action only if it matches the actual action\n",
    "    if predicted_action == actual_action:\n",
    "        predicted_reward = rewards[state_index + 1]  # Reward for the correct prediction\n",
    "        cumulative_predicted_reward += predicted_reward\n",
    "\n",
    "    # Get actual reward for the ground truth action\n",
    "    actual_reward = rewards[state_index + 1]\n",
    "    cumulative_actual_reward += actual_reward\n",
    "\n",
    "    # Optional: Log progress\n",
    "    if state_index % 100 == 0:  # Adjust logging frequency as needed\n",
    "        print(f\"Processed state {state_index}/{n_states - 1}\")\n",
    "        print(f\"Current Predicted Reward: {cumulative_predicted_reward}\")\n",
    "        print(f\"Current Actual Reward: {cumulative_actual_reward}\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Cumulative Predicted Reward: {cumulative_predicted_reward}\")\n",
    "print(f\"Cumulative Actual Reward: {cumulative_actual_reward}\")\n",
    "\n",
    "# Optionally calculate efficiency\n",
    "efficiency = (\n",
    "    ((cumulative_predicted_reward - cumulative_actual_reward) / abs(cumulative_actual_reward)) * 100\n",
    "    if cumulative_actual_reward != 0\n",
    "    else 0\n",
    ")\n",
    "\n",
    "print(f\"Prediction Efficiency: {efficiency:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 38.17%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "correct_predictions = 0\n",
    "for state_index in range(n_states):\n",
    "    predicted_action = np.argmax(q_table[state_index])  # Predicted action\n",
    "    actual_action = train_data[\"action_num\"].iloc[state_index]  # Actual action\n",
    "    if predicted_action == actual_action:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / n_states\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[70 49 27]\n",
      " [40 36 31]\n",
      " [35 27 23]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "y_true = train_data[\"action_num\"]  # Actual actions\n",
    "y_pred = [np.argmax(q_table[state_index]) for state_index in range(n_states)]  # Predicted actions\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_reward(action: str, is_short: int):\n",
    "    m = train_data[(train_data['predicted_action'] == f'{action}') & (train_data['is_short'] == is_short)]\n",
    "    counts = m['is_short'].value_counts()\n",
    "    total_reward = m['reward'].cumsum()[-1:].values[0]\n",
    "    wins = len(m[m['reward'] > 0])\n",
    "    losses = len(m[m['reward'] <= 0])\n",
    "    return {\n",
    "        'counts': counts.get(is_short),\n",
    "        'total reward': total_reward,\n",
    "        'winrate': f'{wins * 100 / (losses + wins):.2f}%',\n",
    "        'per trade profit': m[m['reward'] > 0]['reward'].sum() / wins,\n",
    "        'per trade loss': m[m['reward'] <= 0]['reward'].sum() / losses\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2789499/3005952004.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  'per trade loss': m[m['reward'] <= 0]['reward'].sum() / losses\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'counts': 46,\n",
       " 'total reward': 1765.7819151800002,\n",
       " 'winrate': '100.00%',\n",
       " 'per trade profit': 38.38656337347827,\n",
       " 'per trade loss': nan}"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_reward('do_nothing', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go_long 0: {'counts': 84, 'total reward': 4959.207558579998, 'winrate': '100.00%', 'per trade profit': 59.03818522119047, 'per trade loss': nan}\n",
      "go_long 1: {'counts': 61, 'total reward': 1895.0094862000003, 'winrate': '100.00%', 'per trade profit': 31.06572928196721, 'per trade loss': nan}\n",
      "go_short 0: {'counts': 59, 'total reward': 2819.161270869999, 'winrate': '100.00%', 'per trade profit': 47.78239442152542, 'per trade loss': nan}\n",
      "go_short 1: {'counts': 53, 'total reward': 2018.8578161799994, 'winrate': '100.00%', 'per trade profit': 38.0916569090566, 'per trade loss': nan}\n",
      "do_nothing 0: {'counts': 35, 'total reward': 1159.19880348, 'winrate': '100.00%', 'per trade profit': 33.11996581371428, 'per trade loss': nan}\n",
      "do_nothing 1: {'counts': 46, 'total reward': 1765.7819151800002, 'winrate': '100.00%', 'per trade profit': 38.38656337347827, 'per trade loss': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2789499/3005952004.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  'per trade loss': m[m['reward'] <= 0]['reward'].sum() / losses\n"
     ]
    }
   ],
   "source": [
    "dirs = [0,1]\n",
    "for action in action_mapping.keys():\n",
    "    for is_short in dirs:\n",
    "        try:\n",
    "            print(f'{action} {is_short}: {action_reward(action, is_short)}')\n",
    "        except IndexError as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_action\n",
      "go_long       145\n",
      "go_short      112\n",
      "do_nothing     81\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data['predicted_action'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef correct_action(row):\\n    if row[\\'predicted_action\\'] == \\'go_long\\' and row[\\'is_short\\'] == 1 and row[\\'reward\\'] > 0:\\n        return \\'go_short\\'\\n    if row[\\'predicted_action\\'] == \\'go_short\\' and row[\\'is_short\\'] == 0 and row[\\'reward\\'] > 0:\\n        return \\'go_long\\'\\n    if row[\\'predicted_action\\'] == \\'do_nothing\\' and row[\\'is_short\\'] == 1 and row[\\'reward\\'] > 0:\\n        return \\'go_short\\'\\n    if row[\\'predicted_action\\'] == \\'do_nothing\\' and row[\\'is_short\\'] == 0 and row[\\'reward\\'] > 0:\\n        return \\'go_long\\'\\n    return row[\\'action\\']\\n\\ndef refiner_action(version: str, data: DataFrame = None) -> DataFrame:\\n    data[\\'refined-action\\'] = data.apply(lambda x: correct_action(x), axis=1)\\n    # Validation: Ensure we\\'re fixing the 751 misclassified entries\\n    misclassified = data[\\n        (data[\\'predicted_action\\'] == \\'go_long\\') & \\n        (data[\\'refined-action\\'] == \\'go_short\\')\\n    ]\\n    # Add this after applying refined-action\\n    \\n    confusion_matrix = pd.crosstab(\\n        data[\\'refined-action\\'], \\n        data[\\'predicted_action\\'],  # Assuming you have ground truth column\\n        rownames=[\\'refined\\'],\\n        colnames=[\\'predicted\\']\\n    )\\n\\n    print(\"Updated Confusion Matrix:\")\\n    print(confusion_matrix) \\n    print(f\"Corrected {len(misclassified)} go_long->go_short misclassifications\")\\n    \\n    filename = f\\'../spreadsheets/rlhf_large_{version}_refined.csv\\'\\n    data.to_csv(filename, index=False)\\n    return data\\n    '"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create corrected action\n",
    "'''\n",
    "def correct_action(row):\n",
    "    if row['predicted_action'] == 'go_long' and row['is_short'] == 1 and row['reward'] > 0:\n",
    "        return 'go_short'\n",
    "    if row['predicted_action'] == 'go_short' and row['is_short'] == 0 and row['reward'] > 0:\n",
    "        return 'go_long'\n",
    "    if row['predicted_action'] == 'do_nothing' and row['is_short'] == 1 and row['reward'] > 0:\n",
    "        return 'go_short'\n",
    "    if row['predicted_action'] == 'do_nothing' and row['is_short'] == 0 and row['reward'] > 0:\n",
    "        return 'go_long'\n",
    "    return row['action']\n",
    "\n",
    "def refiner_action(version: str, data: DataFrame = None) -> DataFrame:\n",
    "    data['refined-action'] = data.apply(lambda x: correct_action(x), axis=1)\n",
    "    # Validation: Ensure we're fixing the 751 misclassified entries\n",
    "    misclassified = data[\n",
    "        (data['predicted_action'] == 'go_long') & \n",
    "        (data['refined-action'] == 'go_short')\n",
    "    ]\n",
    "    # Add this after applying refined-action\n",
    "    \n",
    "    confusion_matrix = pd.crosstab(\n",
    "        data['refined-action'], \n",
    "        data['predicted_action'],  # Assuming you have ground truth column\n",
    "        rownames=['refined'],\n",
    "        colnames=['predicted']\n",
    "    )\n",
    "\n",
    "    print(\"Updated Confusion Matrix:\")\n",
    "    print(confusion_matrix) \n",
    "    print(f\"Corrected {len(misclassified)} go_long->go_short misclassifications\")\n",
    "    \n",
    "    filename = f'../spreadsheets/rlhf_large_{version}_refined.csv'\n",
    "    data.to_csv(filename, index=False)\n",
    "    return data\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_action(row):\n",
    "    if row['predicted_action'] == 'go_long' and row['is_short'] == 1 and row['reward'] > 0:\n",
    "        row['is_short'] = 0  # Change to long position\n",
    "        return 'go_short'\n",
    "    if row['predicted_action'] == 'go_short' and row['is_short'] == 0 and row['reward'] > 0:\n",
    "        row['is_short'] = 1  # Change to short position\n",
    "        return 'go_long'\n",
    "    if row['predicted_action'] == 'do_nothing' and row['is_short'] == 1 and row['reward'] > 0:\n",
    "        row['is_short'] = 0  # Change to long position\n",
    "        return 'go_short'\n",
    "    if row['predicted_action'] == 'do_nothing' and row['is_short'] == 0 and row['reward'] > 0:\n",
    "        row['is_short'] = 1  # Change to short position\n",
    "        return 'go_long'\n",
    "    return row['action']\n",
    "\n",
    "def refiner_action(version: str, data: pd.DataFrame) -> pd.DataFrame:\n",
    "    data[['refined-action', 'is_short']] = data.apply(lambda x: pd.Series([correct_action(x), x['is_short']]), axis=1)\n",
    "\n",
    "    # Validation: Check if is_short aligns with refined-action\n",
    "    inconsistency = data[\n",
    "        ((data['refined-action'] == 'go_short') & (data['is_short'] == 0)) |\n",
    "        ((data['refined-action'] == 'go_long') & (data['is_short'] == 1))\n",
    "    ]\n",
    "    \n",
    "    print(f\"Number of inconsistent rows: {len(inconsistency)}\")\n",
    "    \n",
    "    # Updated Confusion Matrix\n",
    "    confusion_matrix = pd.crosstab(\n",
    "        data['refined-action'], \n",
    "        data['predicted_action'],\n",
    "        rownames=['refined'],\n",
    "        colnames=['predicted']\n",
    "    )\n",
    "\n",
    "    print(\"Updated Confusion Matrix:\")\n",
    "    print(confusion_matrix)\n",
    "    \n",
    "    filename = f'../spreadsheets/rlhf_large_{version}_refined.csv'\n",
    "    data.to_csv(filename, index=False)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/defi/Desktop/portfolio/projects/python/pipeline_defi/'\n",
    "#new_data = pd.read_csv('../spreadsheets/rlhf_small_154nlp.csv') \n",
    "def refine_file(version: str, file) -> DataFrame:\n",
    "    filename = f'{base_dir}{file}.csv'\n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename)\n",
    "    #new_data = prep_data(df0.copy()) if newdf0.empty else prep_data(newdf0.copy())\n",
    "    new_data = prep_data(df)   \n",
    "    print(new_data.columns)\n",
    "    new_train_data = refiner_action(version=version, data=new_data)\n",
    "\n",
    "    #new_data = df0.copy()\n",
    "    print(new_train_data.columns)\n",
    "\n",
    "    new_train_data['nlpreds'] = new_train_data['predicted_action']\n",
    "    #new_data['action'] = new_train_data['refined-action']\n",
    "    return new_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/defi/Desktop/portfolio/projects/python/pipeline_defi/lean_df_99rl.csv\n",
      "Index(['open', 'high', 'ema-26', 'ema-12', 'low', 'mean-grad-hist', 'close',\n",
      "       'volume', 'sma-05', 'sma-07', 'sma-25', 'long_jcrosk', 'short_kdj',\n",
      "       'sma-compare', 'ask', 'bid', 'is_short', 'nlpreds', 'action',\n",
      "       'predicted_action', 'reward'],\n",
      "      dtype='object')\n",
      "Number of inconsistent rows: 208\n",
      "Updated Confusion Matrix:\n",
      "predicted   do_nothing  go_long  go_short\n",
      "refined                                  \n",
      "do_nothing          36      161        97\n",
      "go_long             32       53        30\n",
      "go_short            53       93        77\n",
      "Index(['open', 'high', 'ema-26', 'ema-12', 'low', 'mean-grad-hist', 'close',\n",
      "       'volume', 'sma-05', 'sma-07', 'sma-25', 'long_jcrosk', 'short_kdj',\n",
      "       'sma-compare', 'ask', 'bid', 'is_short', 'nlpreds', 'action',\n",
      "       'predicted_action', 'reward', 'refined-action'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "newdf0 = refine_file('99rl', 'lean_df_99rl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_action\n",
      "go_long       307\n",
      "go_short      204\n",
      "do_nothing    121\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(newdf0['predicted_action'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open                                                     23266.377488\n",
       "high                                                     23815.891006\n",
       "ema-26                                                   23462.465994\n",
       "ema-12                                                   23670.602485\n",
       "low                                                      22239.907761\n",
       "mean-grad-hist                                                     53\n",
       "close                                                    23020.305091\n",
       "volume                                                  544466438.655\n",
       "sma-05                                                   23320.971103\n",
       "sma-07                                                   23369.716887\n",
       "sma-25                                                   23740.970138\n",
       "long_jcrosk                                                        30\n",
       "short_kdj                                                           0\n",
       "sma-compare                                                        48\n",
       "ask                                                  265579216.539399\n",
       "bid                                                  278887222.115601\n",
       "is_short                                                          169\n",
       "nlpreds             go_shortgo_shortgo_shortgo_shortgo_shortgo_sho...\n",
       "action              go_shortgo_longgo_shortgo_longdo_nothingdo_not...\n",
       "predicted_action    go_shortgo_shortgo_shortgo_shortgo_shortgo_sho...\n",
       "reward                                                    1545.530101\n",
       "refined-action      go_shortgo_longgo_shortgo_longdo_nothingdo_not...\n",
       "dtype: object"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf0[(newdf0['predicted_action'] == 'go_short') & (newdf0['is_short'] == 1)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlpreds\n",
      "go_long       307\n",
      "go_short      204\n",
      "do_nothing    121\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(newdf0['nlpreds'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "refined-action\n",
       "do_nothing    294\n",
       "go_short      223\n",
       "go_long       115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf0['refined-action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action\n",
       "do_nothing    294\n",
       "go_short      231\n",
       "go_long       107\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf0['action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4214.0592444799995\n"
     ]
    }
   ],
   "source": [
    "print(newdf0[(newdf0['nlpreds'] == 'go_short') & (newdf0['reward'] >  0)]['reward'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3170.03034079\n"
     ]
    }
   ],
   "source": [
    "print(train_data[(train_data['nlpreds'] == 'go_short') & (train_data['reward'] >  0)]['reward'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list of rewards for each episode\n",
    "#rewards_per_episode = [...]  # Populate this with your actual data\n",
    "\n",
    "plt.plot(rewards_per_episode)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Rewards per Episode')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tuning with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning\n",
    "\n",
    "def train_q_learning(alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes, n_states, n_actions, rewards):\n",
    "    q_table = np.zeros((n_states, n_actions))\n",
    "    rewards_per_episode = []\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        current_state = np.random.randint(0, n_states)\n",
    "        total_reward = 0\n",
    "\n",
    "        while current_state < n_states - 1:\n",
    "            if np.random.uniform(0, 1) < epsilon:\n",
    "                action = np.random.randint(0, n_actions)\n",
    "            else:\n",
    "                action = np.argmax(q_table[current_state])\n",
    "\n",
    "            next_state = current_state + 1  # Adjust based on environment logic\n",
    "            reward = rewards[next_state]\n",
    "\n",
    "            best_next_action = np.argmax(q_table[next_state])\n",
    "            q_table[current_state, action] += alpha * (\n",
    "                reward + gamma * q_table[next_state, best_next_action] - q_table[current_state, action]\n",
    "            )\n",
    "\n",
    "            total_reward += reward\n",
    "            current_state = next_state\n",
    "\n",
    "        rewards_per_episode.append(total_reward)\n",
    "        epsilon = max(min_epsilon, epsilon * decay_rate)\n",
    "\n",
    "    return q_table, rewards_per_episode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_q_learning_reward_weighted(q_table, n_states, train_data, rewards):\n",
    "    correct_predictions = 0\n",
    "    total_reward = 0\n",
    "    reward_weighted_accuracy = []\n",
    "\n",
    "    for state_index in range(n_states):\n",
    "        predicted_action = np.argmax(q_table[state_index])  # Predicted action\n",
    "        actual_action = train_data[\"action_num\"].iloc[state_index]  # Actual action\n",
    "        reward = rewards[state_index]  # Reward for the action\n",
    "\n",
    "        if predicted_action == actual_action:\n",
    "            correct_predictions += 1\n",
    "            total_reward += reward\n",
    "\n",
    "        accuracy = correct_predictions / (state_index + 1)\n",
    "        reward_weighted_accuracy.append(total_reward / (state_index + 1))\n",
    "\n",
    "        # Optional: Log progress\n",
    "        if state_index % 100 == 0:\n",
    "            print(f\"Processed state {state_index}/{n_states} - Accuracy: {accuracy * 100:.2f}%, Reward-weighted Accuracy: {reward_weighted_accuracy[-1]}\")\n",
    "\n",
    "    final_reward_weighted_accuracy = total_reward / n_states\n",
    "    return final_reward_weighted_accuracy * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_q_learning_prediction_efficiency(q_table, n_states, train_data, rewards):\n",
    "    # Initialize cumulative rewards\n",
    "    cumulative_predicted_reward = 0\n",
    "    cumulative_actual_reward = 0\n",
    "\n",
    "    # Iterate through states to calculate rewards\n",
    "    for state_index in range(n_states - 1):\n",
    "        # Predicted action from Q-table\n",
    "        predicted_action = np.argmax(q_table[state_index])  # Best action for the current state\n",
    "        # Actual action from the ground truth\n",
    "        actual_action = train_data[\"action_num\"].iloc[state_index]\n",
    "\n",
    "        # Get reward for predicted action only if it matches the actual action\n",
    "        if predicted_action == actual_action:\n",
    "            predicted_reward = rewards[state_index + 1]  # Reward for the correct prediction\n",
    "            cumulative_predicted_reward += predicted_reward\n",
    "\n",
    "        # Get actual reward for the ground truth action\n",
    "        actual_reward = rewards[state_index + 1]\n",
    "        cumulative_actual_reward += actual_reward\n",
    "    return cumulative_predicted_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_data = newdf0\\ntrain_data[\\'action_num\\'] = train_data[f\"refined-action\"].map(action_mapping)\\ndef random_search_reward_weighted(n_iter, param_grid, n_states, n_actions, rewards, train_data):\\n    best_params = None\\n    best_reward_weighted_accuracy = float(\\'-inf\\')\\n\\n    for _ in tqdm(range(n_iter), desc=\"Searching for params ...\"):\\n        alpha = random.choice(param_grid[\\'alpha\\'])\\n        gamma = random.choice(param_grid[\\'gamma\\'])\\n        epsilon = random.choice(param_grid[\\'epsilon\\'])\\n        min_epsilon = random.choice(param_grid[\\'decay_rate\\'])\\n        decay_rate = random.choice(param_grid[\\'decay_rate\\'])\\n        n_episodes = random.choice(param_grid[\\'n_episodes\\'])\\n\\n        q_table, _ = train_q_learning(alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes, n_states, n_actions, rewards)\\n        reward_weighted_accuracy = evaluate_q_learning_reward_weighted(q_table, n_states, train_data, rewards)\\n\\n        if reward_weighted_accuracy > best_reward_weighted_accuracy:\\n            best_reward_weighted_accuracy = reward_weighted_accuracy\\n            best_params = (alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes)\\n\\n        print(f\"Iteration Reward-weighted Accuracy: {reward_weighted_accuracy:.2f}%, Best Reward-weighted Accuracy: {best_reward_weighted_accuracy:.2f}%\")\\n\\n    return best_params, best_reward_weighted_accuracy\\n\\n# Define the parameter grid\\nparam_grid = {\\n    \\'alpha\\': [0.01, 0.05, 0.1, 0.2, 0.25, 0.3, 0.5, 0.7, 0.9, 1],\\n    \\'gamma\\': [0.75, 0.85, 0.9, 0.95, 0.99],\\n    \\'epsilon\\': [1.0, 0.5, 0.1, 0.05, 0.01],\\n    \\'min_epsilon\\': [0.05, 0.01, 0.005, 0.001, 0.001],\\n    \\'decay_rate\\': [0.95, 0.96, 0.97, 0.99, 0.995, 0.997, 0.999],\\n    \\'n_episodes\\': [1500, 4000,6000, 8000, 9000, 10000, 11000, 12000, 14000, 18000, 21000, 24000, 28000]\\n}\\n\\n# Perform Random Search\\nbest_params, best_reward_weighted_accuracy = random_search_reward_weighted(50, param_grid, n_states, n_actions, rewards, train_data)\\nprint(f\"Best Hyperparameters: {best_params}\")\\nprint(f\"Best Reward-weighted Accuracy: {best_reward_weighted_accuracy:.2f}%\")\\n\\n'"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_data = newdf0\n",
    "train_data['action_num'] = train_data[f\"refined-action\"].map(action_mapping)\n",
    "def random_search_reward_weighted(n_iter, param_grid, n_states, n_actions, rewards, train_data):\n",
    "    best_params = None\n",
    "    best_reward_weighted_accuracy = float('-inf')\n",
    "\n",
    "    for _ in tqdm(range(n_iter), desc=\"Searching for params ...\"):\n",
    "        alpha = random.choice(param_grid['alpha'])\n",
    "        gamma = random.choice(param_grid['gamma'])\n",
    "        epsilon = random.choice(param_grid['epsilon'])\n",
    "        min_epsilon = random.choice(param_grid['decay_rate'])\n",
    "        decay_rate = random.choice(param_grid['decay_rate'])\n",
    "        n_episodes = random.choice(param_grid['n_episodes'])\n",
    "\n",
    "        q_table, _ = train_q_learning(alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes, n_states, n_actions, rewards)\n",
    "        reward_weighted_accuracy = evaluate_q_learning_reward_weighted(q_table, n_states, train_data, rewards)\n",
    "\n",
    "        if reward_weighted_accuracy > best_reward_weighted_accuracy:\n",
    "            best_reward_weighted_accuracy = reward_weighted_accuracy\n",
    "            best_params = (alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes)\n",
    "\n",
    "        print(f\"Iteration Reward-weighted Accuracy: {reward_weighted_accuracy:.2f}%, Best Reward-weighted Accuracy: {best_reward_weighted_accuracy:.2f}%\")\n",
    "\n",
    "    return best_params, best_reward_weighted_accuracy\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.05, 0.1, 0.2, 0.25, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "    'gamma': [0.75, 0.85, 0.9, 0.95, 0.99],\n",
    "    'epsilon': [1.0, 0.5, 0.1, 0.05, 0.01],\n",
    "    'min_epsilon': [0.05, 0.01, 0.005, 0.001, 0.001],\n",
    "    'decay_rate': [0.95, 0.96, 0.97, 0.99, 0.995, 0.997, 0.999],\n",
    "    'n_episodes': [1500, 4000,6000, 8000, 9000, 10000, 11000, 12000, 14000, 18000, 21000, 24000, 28000]\n",
    "}\n",
    "\n",
    "# Perform Random Search\n",
    "best_params, best_reward_weighted_accuracy = random_search_reward_weighted(50, param_grid, n_states, n_actions, rewards, train_data)\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Reward-weighted Accuracy: {best_reward_weighted_accuracy:.2f}%\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_data = newdf0\\ntrain_data[\\'action_num\\'] = train_data[f\"refined-action\"].map(action_mapping)\\ndef random_search_prediction_efficiency(n_iter, param_grid, n_states, n_actions, rewards, train_data):\\n    best_params = None\\n    best_cumulative_pred_reward = float(\\'-inf\\')\\n\\n    for _ in tqdm(range(n_iter), desc=\"Searching for params ...\"):\\n        alpha = random.choice(param_grid[\\'alpha\\'])\\n        gamma = random.choice(param_grid[\\'gamma\\'])\\n        epsilon = random.choice(param_grid[\\'epsilon\\'])\\n        min_epsilon = random.choice(param_grid[\\'decay_rate\\'])\\n        decay_rate = random.choice(param_grid[\\'decay_rate\\'])\\n        n_episodes = random.choice(param_grid[\\'n_episodes\\'])\\n\\n        q_table, _ = train_q_learning(alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes, n_states, n_actions, rewards)\\n        cumulative_pred_reward = evaluate_q_learning_prediction_efficiency(q_table, n_states, train_data, rewards)\\n\\n        if cumulative_pred_reward > best_cumulative_pred_reward:\\n            best_cumulative_pred_reward = cumulative_pred_reward\\n            best_params = (alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes)\\n\\n        print(f\"Iteration cumulative predicted reward: {cumulative_pred_reward:.2f}%, Best cumulative predicted reward: {best_cumulative_pred_reward:.2f}%\")\\n\\n    return best_params, best_cumulative_pred_reward\\n\\n# Define the parameter grid\\nparam_grid = {\\n    \\'alpha\\': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.25, 0.3, 0.5, 0.7, 0.9, 1],\\n    \\'gamma\\': [0.75, 0.85, 0.9, 0.95, 0.99],\\n    \\'epsilon\\': [1.0, 0.5, 0.1, 0.05, 0.01, 0.005],\\n    \\'min_epsilon\\': [0.05, 0.01, 0.005, 0.001, 0.001],\\n    \\'decay_rate\\': [0.95, 0.99, 0.995, 0.997, 0.999],\\n    \\'n_episodes\\': [1500, 4000,6000, 8000, 9000, 10000, 11000, 12000, 14000, 16000, 18000, 20000, 22000, 24000, 26000, 28000, 30000]\\n}\\n\\n# Perform Random Search\\nbest_params, best_cumulative_pred_reward = random_search_prediction_efficiency(50, param_grid, n_states, n_actions, rewards, train_data)\\nprint(f\"Best Hyperparameters: {best_params}\")\\nprint(f\"Best cumulative predicted reward: {best_cumulative_pred_reward:.2f}%\")\\n'"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_data = newdf0\n",
    "train_data['action_num'] = train_data[f\"refined-action\"].map(action_mapping)\n",
    "def random_search_prediction_efficiency(n_iter, param_grid, n_states, n_actions, rewards, train_data):\n",
    "    best_params = None\n",
    "    best_cumulative_pred_reward = float('-inf')\n",
    "\n",
    "    for _ in tqdm(range(n_iter), desc=\"Searching for params ...\"):\n",
    "        alpha = random.choice(param_grid['alpha'])\n",
    "        gamma = random.choice(param_grid['gamma'])\n",
    "        epsilon = random.choice(param_grid['epsilon'])\n",
    "        min_epsilon = random.choice(param_grid['decay_rate'])\n",
    "        decay_rate = random.choice(param_grid['decay_rate'])\n",
    "        n_episodes = random.choice(param_grid['n_episodes'])\n",
    "\n",
    "        q_table, _ = train_q_learning(alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes, n_states, n_actions, rewards)\n",
    "        cumulative_pred_reward = evaluate_q_learning_prediction_efficiency(q_table, n_states, train_data, rewards)\n",
    "\n",
    "        if cumulative_pred_reward > best_cumulative_pred_reward:\n",
    "            best_cumulative_pred_reward = cumulative_pred_reward\n",
    "            best_params = (alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes)\n",
    "\n",
    "        print(f\"Iteration cumulative predicted reward: {cumulative_pred_reward:.2f}%, Best cumulative predicted reward: {best_cumulative_pred_reward:.2f}%\")\n",
    "\n",
    "    return best_params, best_cumulative_pred_reward\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.25, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "    'gamma': [0.75, 0.85, 0.9, 0.95, 0.99],\n",
    "    'epsilon': [1.0, 0.5, 0.1, 0.05, 0.01, 0.005],\n",
    "    'min_epsilon': [0.05, 0.01, 0.005, 0.001, 0.001],\n",
    "    'decay_rate': [0.95, 0.99, 0.995, 0.997, 0.999],\n",
    "    'n_episodes': [1500, 4000,6000, 8000, 9000, 10000, 11000, 12000, 14000, 16000, 18000, 20000, 22000, 24000, 26000, 28000, 30000]\n",
    "}\n",
    "\n",
    "# Perform Random Search\n",
    "best_params, best_cumulative_pred_reward = random_search_prediction_efficiency(50, param_grid, n_states, n_actions, rewards, train_data)\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best cumulative predicted reward: {best_cumulative_pred_reward:.2f}%\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
