{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas import DataFrame\n",
    "import pickle, random\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import KDTree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df0 = pd.read_csv('../spreadsheets/rlhf_20250104_6.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_159nlp.csv') # Best\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_1064_2.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_1072.csv') # 0.05, 0.95, 1.0, 0.999, 0.995, 12000\n",
    "#df0 = pd.read_csv('../spreadsheets/shufled_rlhf_11rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_12rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_15rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_19rl.csv') # 0.005, 0.75, 0.1, 0.95, 0.999, 12000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_23rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_24rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_25rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_26rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_157nlp.csv') # 0.7, 0.95, 0.5, 0.999, 0.99, 16000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_29rl.csv') # 0.9, 0.9, 0.005, 0.95, 0.999, 10000, 0.9, 0.95, 1.0, 0.99, 0.99, 8000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_30rl.csv') # \n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_32rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_33rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_35rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_37rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_27rl2.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_38rl.csv')\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_42rl.csv') # 0.01, 0.99, 1.0, 0.95, 0.99, 16000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_large_154nlp.csv') # 0.9, 0.9, 0.005, 0.95, 0.999, 10000\n",
    "#df0 = pd.read_csv('../spreadsheets/rlhf_bid_47rl_refined.csv')\n",
    "df0 = pd.read_csv('../spreadsheets/rlhf_large_50rl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['ask'] = df0['close'] * df0['volume']/(df0['close'] + df0['open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['bid'] = df0['open'] * df0['volume']/(df0['close'] + df0['open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'open', 'high', 'ema-26', 'ema-12', 'low',\n",
       "       'mean-grad-hist', 'close', 'volume', 'sma-25', 'long_jcrosk',\n",
       "       'short_kdj', 'sma-05', 'sma-07', 'sma-compare', 'is_short', 'action',\n",
       "       'imit-action', 'nlpreds', 'reward', 'ask', 'bid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>ema-26</th>\n",
       "      <th>ema-12</th>\n",
       "      <th>low</th>\n",
       "      <th>mean-grad-hist</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sma-25</th>\n",
       "      <th>...</th>\n",
       "      <th>sma-05</th>\n",
       "      <th>sma-07</th>\n",
       "      <th>sma-compare</th>\n",
       "      <th>is_short</th>\n",
       "      <th>action</th>\n",
       "      <th>imit-action</th>\n",
       "      <th>nlpreds</th>\n",
       "      <th>reward</th>\n",
       "      <th>ask</th>\n",
       "      <th>bid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.304000</td>\n",
       "      <td>10.332000</td>\n",
       "      <td>10.437047</td>\n",
       "      <td>10.597291</td>\n",
       "      <td>10.18100</td>\n",
       "      <td>0</td>\n",
       "      <td>10.326000</td>\n",
       "      <td>3.586200e+05</td>\n",
       "      <td>10.646800</td>\n",
       "      <td>...</td>\n",
       "      <td>10.363000</td>\n",
       "      <td>10.348714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_short</td>\n",
       "      <td>-11.459495</td>\n",
       "      <td>1.795012e+05</td>\n",
       "      <td>1.791188e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>445.750000</td>\n",
       "      <td>446.110000</td>\n",
       "      <td>444.906188</td>\n",
       "      <td>443.432365</td>\n",
       "      <td>443.10000</td>\n",
       "      <td>1</td>\n",
       "      <td>443.530000</td>\n",
       "      <td>1.751153e+03</td>\n",
       "      <td>442.440400</td>\n",
       "      <td>...</td>\n",
       "      <td>445.842000</td>\n",
       "      <td>446.728571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_short</td>\n",
       "      <td>-10.390311</td>\n",
       "      <td>8.733907e+02</td>\n",
       "      <td>8.777623e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>63.920000</td>\n",
       "      <td>63.970000</td>\n",
       "      <td>63.909498</td>\n",
       "      <td>64.056823</td>\n",
       "      <td>62.74000</td>\n",
       "      <td>1</td>\n",
       "      <td>62.760000</td>\n",
       "      <td>1.210974e+04</td>\n",
       "      <td>63.703600</td>\n",
       "      <td>...</td>\n",
       "      <td>64.152000</td>\n",
       "      <td>64.095714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_short</td>\n",
       "      <td>-8.635224</td>\n",
       "      <td>5.999426e+03</td>\n",
       "      <td>6.110315e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.028684</td>\n",
       "      <td>0.029109</td>\n",
       "      <td>0.028890</td>\n",
       "      <td>0.028528</td>\n",
       "      <td>0.02868</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029104</td>\n",
       "      <td>7.112435e+08</td>\n",
       "      <td>0.028402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028976</td>\n",
       "      <td>0.028999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>go_long</td>\n",
       "      <td>go_long</td>\n",
       "      <td>go_short</td>\n",
       "      <td>-6.819206</td>\n",
       "      <td>3.582064e+08</td>\n",
       "      <td>3.530371e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.362600</td>\n",
       "      <td>1.362900</td>\n",
       "      <td>1.367365</td>\n",
       "      <td>1.377128</td>\n",
       "      <td>1.33500</td>\n",
       "      <td>1</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>2.572130e+05</td>\n",
       "      <td>1.374716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.357700</td>\n",
       "      <td>1.365729</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_long</td>\n",
       "      <td>-9.058079</td>\n",
       "      <td>1.275311e+05</td>\n",
       "      <td>1.296819e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        open        high      ema-26      ema-12        low  \\\n",
       "0           0   10.304000   10.332000   10.437047   10.597291   10.18100   \n",
       "1           1  445.750000  446.110000  444.906188  443.432365  443.10000   \n",
       "2           2   63.920000   63.970000   63.909498   64.056823   62.74000   \n",
       "3           3    0.028684    0.029109    0.028890    0.028528    0.02868   \n",
       "4           4    1.362600    1.362900    1.367365    1.377128    1.33500   \n",
       "\n",
       "   mean-grad-hist       close        volume      sma-25  ...      sma-05  \\\n",
       "0               0   10.326000  3.586200e+05   10.646800  ...   10.363000   \n",
       "1               1  443.530000  1.751153e+03  442.440400  ...  445.842000   \n",
       "2               1   62.760000  1.210974e+04   63.703600  ...   64.152000   \n",
       "3               0    0.029104  7.112435e+08    0.028402  ...    0.028976   \n",
       "4               1    1.340000  2.572130e+05    1.374716  ...    1.357700   \n",
       "\n",
       "       sma-07  sma-compare  is_short    action  imit-action   nlpreds  \\\n",
       "0   10.348714            0         1  go_short     go_short  go_short   \n",
       "1  446.728571            0         1  go_short     go_short  go_short   \n",
       "2   64.095714            0         1  go_short     go_short  go_short   \n",
       "3    0.028999            0         0   go_long      go_long  go_short   \n",
       "4    1.365729            1         1  go_short     go_short   go_long   \n",
       "\n",
       "      reward           ask           bid  \n",
       "0 -11.459495  1.795012e+05  1.791188e+05  \n",
       "1 -10.390311  8.733907e+02  8.777623e+02  \n",
       "2  -8.635224  5.999426e+03  6.110315e+03  \n",
       "3  -6.819206  3.582064e+08  3.530371e+08  \n",
       "4  -9.058079  1.275311e+05  1.296819e+05  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df0.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action\n",
       "go_short    21897\n",
       "go_long      1003\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#action_mapping = {\"go_long\": 0, \"go_short\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df: DataFrame) -> DataFrame:\n",
    "    train_data = pd.DataFrame()\n",
    "    for col in df.columns:\n",
    "        col_name = col.split(' ')[0]\n",
    "        train_data[f'{col_name}'] = df[col]\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf0 = pd.DataFrame()\n",
    "train_data = df0 if newdf0.empty else newdf0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>ema-26</th>\n",
       "      <th>ema-12</th>\n",
       "      <th>low</th>\n",
       "      <th>mean-grad-hist</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sma-25</th>\n",
       "      <th>...</th>\n",
       "      <th>sma-05</th>\n",
       "      <th>sma-07</th>\n",
       "      <th>sma-compare</th>\n",
       "      <th>is_short</th>\n",
       "      <th>action</th>\n",
       "      <th>imit-action</th>\n",
       "      <th>nlpreds</th>\n",
       "      <th>reward</th>\n",
       "      <th>ask</th>\n",
       "      <th>bid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.304</td>\n",
       "      <td>10.332</td>\n",
       "      <td>10.437047</td>\n",
       "      <td>10.597291</td>\n",
       "      <td>10.181</td>\n",
       "      <td>0</td>\n",
       "      <td>10.326</td>\n",
       "      <td>358620.000</td>\n",
       "      <td>10.6468</td>\n",
       "      <td>...</td>\n",
       "      <td>10.363</td>\n",
       "      <td>10.348714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_short</td>\n",
       "      <td>-11.459495</td>\n",
       "      <td>179501.217644</td>\n",
       "      <td>179118.782356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>445.750</td>\n",
       "      <td>446.110</td>\n",
       "      <td>444.906188</td>\n",
       "      <td>443.432365</td>\n",
       "      <td>443.100</td>\n",
       "      <td>1</td>\n",
       "      <td>443.530</td>\n",
       "      <td>1751.153</td>\n",
       "      <td>442.4404</td>\n",
       "      <td>...</td>\n",
       "      <td>445.842</td>\n",
       "      <td>446.728571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_short</td>\n",
       "      <td>go_short</td>\n",
       "      <td>-10.390311</td>\n",
       "      <td>873.390709</td>\n",
       "      <td>877.762291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     open     high      ema-26      ema-12      low  \\\n",
       "0           0   10.304   10.332   10.437047   10.597291   10.181   \n",
       "1           1  445.750  446.110  444.906188  443.432365  443.100   \n",
       "\n",
       "   mean-grad-hist    close      volume    sma-25  ...   sma-05      sma-07  \\\n",
       "0               0   10.326  358620.000   10.6468  ...   10.363   10.348714   \n",
       "1               1  443.530    1751.153  442.4404  ...  445.842  446.728571   \n",
       "\n",
       "   sma-compare  is_short    action  imit-action   nlpreds     reward  \\\n",
       "0            0         1  go_short     go_short  go_short -11.459495   \n",
       "1            0         1  go_short     go_short  go_short -10.390311   \n",
       "\n",
       "             ask            bid  \n",
       "0  179501.217644  179118.782356  \n",
       "1     873.390709     877.762291  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = ['ask','bid','sma-compare','is_short']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode actions into numerical values\n",
    "action_mapping = {\"go_long\": 0, \"go_short\": 1, \"do_nothing\": 2}\n",
    "action_col = 'nlpreds' if newdf0.empty else 'refined-action'\n",
    "train_data[\"action_num\"] = train_data[f\"{action_col}\"].map(action_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'open', 'high', 'ema-26', 'ema-12', 'low',\n",
       "       'mean-grad-hist', 'close', 'volume', 'sma-25', 'long_jcrosk',\n",
       "       'short_kdj', 'sma-05', 'sma-07', 'sma-compare', 'is_short', 'action',\n",
       "       'imit-action', 'nlpreds', 'reward', 'ask', 'bid', 'action_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RL parameters\n",
    "#states = train_data[[\"sma-05\", \"sma-07\", \"sma-25\", \"sma-compare\", \"is_short\"]].values  # Include binary_state\n",
    "states = train_data[new_cols].values\n",
    "\n",
    "actions = list(action_mapping.values())  # Action space\n",
    "rewards = train_data[\"reward\"].values  # Rewards\n",
    "n_states = states.shape[0]\n",
    "n_actions = len(actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Q-table\n",
    "q_table = np.zeros((n_states, n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyperparameters = [\n",
    "    [0.1, 0.9, 0.1, 0.99, 0.995, 4000],\n",
    "    [0.005, 0.75, 0.1, 0.95, 0.999, 12000],\n",
    "    [0.001, 0.75, 1.0, 0.99, 0.99, 30000],\n",
    "    [1, 0.75, 0.005, 0.95, 0.95, 22000],\n",
    "    [0.01, 0.99, 1.0, 0.95, 0.99, 16000],\n",
    "    [0.7, 0.99, 1.0, 0.95, 0.997, 8000],\n",
    "    [0.01, 0.95, 1.0, 0.997, 0.995, 26000],\n",
    "    [0.25, 0.95, 0.01, 0.997, 0.999, 14000],\n",
    "    [0.5, 0.85, 0.5, 0.997, 0.997, 14000],\n",
    "    [0.01, 0.85, 0.01, 0.95, 0.95, 12000],\n",
    "    [0.9, 0.99, 0.5, 0.995, 0.95, 12000],\n",
    "    [0.05, 0.9, 0.5, 0.95, 0.999, 4000],\n",
    "    [0.05, 0.99, 0.5, 0.99, 0.997, 6000],\n",
    "    [1, 0.75, 0.05, 0.999, 0.999, 10000],\n",
    "    [0.9, 0.95, 1.0, 0.99, 0.99, 8000],\n",
    "    [0.25, 0.75, 0.01, 0.995, 0.999, 20000],\n",
    "    [0.3, 0.75, 1.0, 0.995, 0.99, 10000],\n",
    "    [1, 0.9, 1.0, 0.999, 0.999, 10000],\n",
    "    [0.7, 0.75, 1.0, 0.97, 0.999, 28000],\n",
    "    [0.05, 0.95, 1.0, 0.999, 0.995, 12000],\n",
    "    [0.7, 0.95, 0.5, 0.999, 0.99, 16000],\n",
    "    [0.25, 0.95, 1.0, 0.99, 0.99, 10000],\n",
    "    [0.25, 0.99, 0.01, 0.997, 0.99, 8000],\n",
    "    [1, 0.95, 0.1, 0.96, 0.96, 12000],\n",
    "    [0.9, 0.9, 0.005, 0.95, 0.999, 10000],\n",
    "    [1, 0.9, 1.0, 0.99, 0.99, 11000],\n",
    "    [0.5, 0.75, 0.005, 0.95, 0.999, 14000]\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [0.1, 0.9, 0.1, 0.99, 0.995, 4000])\n",
      "(1, [0.005, 0.75, 0.1, 0.95, 0.999, 12000])\n",
      "(2, [0.001, 0.75, 1.0, 0.99, 0.99, 30000])\n",
      "(3, [1, 0.75, 0.005, 0.95, 0.95, 22000])\n",
      "(4, [0.01, 0.99, 1.0, 0.95, 0.99, 16000])\n",
      "(5, [0.7, 0.99, 1.0, 0.95, 0.997, 8000])\n",
      "(6, [0.01, 0.95, 1.0, 0.997, 0.995, 26000])\n",
      "(7, [0.25, 0.95, 0.01, 0.997, 0.999, 14000])\n",
      "(8, [0.5, 0.85, 0.5, 0.997, 0.997, 14000])\n",
      "(9, [0.01, 0.85, 0.01, 0.95, 0.95, 12000])\n",
      "(10, [0.9, 0.99, 0.5, 0.995, 0.95, 12000])\n",
      "(11, [0.05, 0.9, 0.5, 0.95, 0.999, 4000])\n",
      "(12, [0.05, 0.99, 0.5, 0.99, 0.997, 6000])\n",
      "(13, [1, 0.75, 0.05, 0.999, 0.999, 10000])\n",
      "(14, [0.9, 0.95, 1.0, 0.99, 0.99, 8000])\n",
      "(15, [0.25, 0.75, 0.01, 0.995, 0.999, 20000])\n",
      "(16, [0.3, 0.75, 1.0, 0.995, 0.99, 10000])\n",
      "(17, [1, 0.9, 1.0, 0.999, 0.999, 10000])\n",
      "(18, [0.7, 0.75, 1.0, 0.97, 0.999, 28000])\n",
      "(19, [0.05, 0.95, 1.0, 0.999, 0.995, 12000])\n",
      "(20, [0.7, 0.95, 0.5, 0.999, 0.99, 16000])\n",
      "(21, [0.25, 0.95, 1.0, 0.99, 0.99, 10000])\n",
      "(22, [0.25, 0.99, 0.01, 0.997, 0.99, 8000])\n",
      "(23, [1, 0.95, 0.1, 0.96, 0.96, 12000])\n",
      "(24, [0.9, 0.9, 0.005, 0.95, 0.999, 10000])\n",
      "(25, [1, 0.9, 1.0, 0.99, 0.99, 11000])\n",
      "(26, [0.5, 0.75, 0.005, 0.95, 0.999, 14000])\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(Hyperparameters):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(*Hyperparameters[0])\n",
    "'''\n",
    "alpha = 1\n",
    "gamma = 0.95\n",
    "epsilon = 0.1\n",
    "min_epsilon = 0.96\n",
    "decay_rate = 0.96\n",
    "n_episodes = 12000\n",
    "'''\n",
    "\n",
    "alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes = Hyperparameters[25] #Hyperparameters[26] #Hyperparameters[24] # Hyperparameters[9] # Hyperparameters[22] #Hyperparameters[6]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_index_mapping(df):\n",
    "    state_to_index = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        state = (row['ask'], row['bid'], row['sma-compare'], row['is_short'])\n",
    "        state_to_index[state] = idx\n",
    "    return state_to_index\n",
    "\n",
    "# Assuming 'df' is your dataframe used during training\n",
    "state_to_index = create_state_index_mapping(train_data)\n",
    "\n",
    "# Save the state_to_index dictionary for later use\n",
    "np.save('bids_state_to_index.npy', state_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to choose an action using epsilon-greedy\n",
    "def choose_action(state, epsilon):\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        return np.random.randint(0, n_actions)  # Explore: random action\n",
    "    else:\n",
    "        return np.argmax(q_table[state])  # Exploit: best known action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:   0%|          | 4/11000 [00:00<07:28, 24.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0/11000 - Total Reward: -16045.28484425999, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:   4%|▎         | 402/11000 [00:26<09:52, 17.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 400/11000 - Total Reward: -18395.921458699988, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:   7%|▋         | 801/11000 [00:54<11:27, 14.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 800/11000 - Total Reward: -14654.508306499967, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  11%|█         | 1202/11000 [01:22<11:50, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1200/11000 - Total Reward: -13288.979864849964, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  15%|█▍        | 1602/11000 [01:49<09:09, 17.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1600/11000 - Total Reward: -17451.530251320004, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  18%|█▊        | 2003/11000 [02:17<07:20, 20.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2000/11000 - Total Reward: -19019.02489482, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  22%|██▏       | 2402/11000 [02:46<11:42, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2400/11000 - Total Reward: -12191.409114939994, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  25%|██▌       | 2803/11000 [03:15<09:02, 15.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2800/11000 - Total Reward: -2029.6355102699372, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  29%|██▉       | 3202/11000 [03:43<10:46, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3200/11000 - Total Reward: -12126.39547588, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  33%|███▎      | 3602/11000 [04:13<07:33, 16.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3600/11000 - Total Reward: -15571.876507109995, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  36%|███▋      | 4003/11000 [04:42<07:39, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4000/11000 - Total Reward: -15899.594813679993, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  40%|████      | 4402/11000 [05:11<08:14, 13.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4400/11000 - Total Reward: -18722.542551069997, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  44%|████▎     | 4802/11000 [05:37<06:35, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4800/11000 - Total Reward: -13820.445671009948, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  47%|████▋     | 5202/11000 [06:04<07:54, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5200/11000 - Total Reward: -13430.042245079949, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  51%|█████     | 5602/11000 [06:32<06:25, 14.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5600/11000 - Total Reward: -2994.9227503899374, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  55%|█████▍    | 6005/11000 [07:00<06:05, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6000/11000 - Total Reward: -18305.009874529987, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  58%|█████▊    | 6404/11000 [07:26<05:10, 14.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6400/11000 - Total Reward: -1053.7838184899865, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  62%|██████▏   | 6804/11000 [07:54<07:59,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6800/11000 - Total Reward: -9123.932868010066, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  65%|██████▌   | 7203/11000 [08:23<04:10, 15.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7200/11000 - Total Reward: -2463.99600991997, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  69%|██████▉   | 7604/11000 [08:51<02:53, 19.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7600/11000 - Total Reward: -12282.443041899995, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  73%|███████▎  | 8002/11000 [09:20<04:34, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8000/11000 - Total Reward: -766.4089097700102, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  76%|███████▋  | 8407/11000 [09:49<02:48, 15.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8400/11000 - Total Reward: -1944.3973785799271, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  80%|████████  | 8804/11000 [10:16<02:06, 17.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8800/11000 - Total Reward: -19031.67555602, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  84%|████████▎ | 9202/11000 [10:43<02:10, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9200/11000 - Total Reward: -18441.43112846999, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  87%|████████▋ | 9603/11000 [11:12<01:24, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9600/11000 - Total Reward: -12368.84414415001, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  91%|█████████ | 10003/11000 [11:41<01:16, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10000/11000 - Total Reward: -17792.900248199996, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  95%|█████████▍| 10404/11000 [12:09<00:36, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10400/11000 - Total Reward: -599.9407400600181, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...:  98%|█████████▊| 10803/11000 [12:37<00:15, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10800/11000 - Total Reward: -12473.802626130011, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating results per episode ...: 100%|██████████| 11000/11000 [12:52<00:00, 14.24it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Set random seed for reproducibility and train the loop\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "# Initialize a list to store rewards per episode\n",
    "rewards_per_episode = []\n",
    "\n",
    "for episode in tqdm(range(n_episodes), desc=\"evaluating results per episode ...\"):\n",
    "    current_state = np.random.randint(0, n_states)  # Random initial state\n",
    "    total_reward = 0  # Initialize total reward for the current episode\n",
    "\n",
    "    while current_state < n_states - 1:\n",
    "        action = choose_action(current_state, epsilon)\n",
    "        \n",
    "        next_state = current_state + 1  # This depends on your environment logic\n",
    "        reward = rewards[next_state]\n",
    "\n",
    "        best_next_action = np.argmax(q_table[next_state])\n",
    "        q_table[current_state, action] += alpha * (\n",
    "            reward + gamma * q_table[next_state, best_next_action] - q_table[current_state, action]\n",
    "        )\n",
    "        \n",
    "        total_reward += reward  # Accumulate reward for the current episode\n",
    "        current_state = next_state  # Move to next state\n",
    "\n",
    "    rewards_per_episode.append(total_reward)  # Store the total reward for the current episode\n",
    "\n",
    "    # Decay epsilon\n",
    "    epsilon = max(min_epsilon, epsilon * decay_rate)\n",
    "\n",
    "    # Optional: Log progress\n",
    "    if episode % 400 == 0:  # Adjust logging frequency as needed\n",
    "        print(f\"Episode {episode}/{n_episodes} - Total Reward: {total_reward}, Epsilon: {epsilon}\")\n",
    "\n",
    "# Example: Save the Q-table\n",
    "np.save(\"bids_q_table.npy\", q_table)\n",
    "\n",
    "# Example: Plotting the rewards\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(rewards_per_episode)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Rewards per Episode')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_q_table(file_path):\n",
    "    return np.load(file_path)\n",
    "\n",
    "def load_state_index_mapping(file_path):\n",
    "    return np.load(file_path, allow_pickle=True).item()\n",
    "\n",
    "loaded_state_to_index = load_state_index_mapping(file_path=\"bids_state_to_index.npy\")\n",
    "loaded_qtable = load_q_table(file_path=\"bids_q_table.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state = (row['open'], row['high'], row['ema-26'], row['ema-12'], row['low'], \\\n",
    "#                 row['mean-grad-hist'], row['close'], row['volume'], row['sma-25'], \\\n",
    "#                 row['long_jcrosk'], row['short_kdj'], row['sma-compare'], row['is_short'])\n",
    "\n",
    "def prep_state(\n",
    "                ask: float, bid: float, sma_compare: int, is_short: int\n",
    "            ):\n",
    "    state = np.array([[ask, bid, sma_compare, is_short]])\n",
    "    if not np.all(np.isfinite(state)):\n",
    "        state = np.nan_to_num(state, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_action(state, q_table, state_to_index, action_mapping, default_action: str = None):\n",
    "    state_tuple = tuple(state.flatten())\n",
    "\n",
    "    state_index = state_to_index.get(state_tuple, -1)\n",
    "    #state_index = loaded_state_to_index.get(state_tuple, -1)\n",
    "    if state_index != -1:\n",
    "        try:\n",
    "            q_values = q_table[state_index]\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            #return default_action\n",
    "    else:\n",
    "        state_tuples = list(state_to_index.keys())\n",
    "        kdtree = KDTree(state_tuples)\n",
    "        distance, index = kdtree.query(state.flatten())\n",
    "        nearest_state_tuple = state_tuples[index]\n",
    "        q_values = loaded_qtable[state_to_index[nearest_state_tuple]]\n",
    "    \n",
    "    #q_values = q_table[state_index]\n",
    "    return [action for action, index in action_mapping.items() if index == np.argmax(q_values)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict an entire range\n",
    "def predict_range(df: DataFrame = train_data) -> DataFrame:\n",
    "    for idx, row in df.iterrows():\n",
    "        state = row[['ask','bid','sma-compare', 'is_short']].values\n",
    "        #q_table = loaded_qtable\n",
    "        #state_to_index = loaded_state_to_index\n",
    "        #action_mapping = {\"go_long\": 0, \"go_short\": 1, \"do_nothing\": 2}\n",
    "        action = predict_action(state, q_table, state_to_index, action_mapping)\n",
    "        df.loc[idx, \"predicted_action\"] = action\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = predict_range(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_action\n",
       "go_long       22566\n",
       "go_short        200\n",
       "do_nothing      134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['predicted_action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_short\n",
       "1    20493\n",
       "0      939\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = train_data[(train_data['predicted_action'] == 'go_long') & (train_data['reward'] > 0)]\n",
    "m['is_short'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "939\n",
      "20493\n"
     ]
    }
   ],
   "source": [
    "longs = dict(m['is_short'].value_counts().items()).get(0)\n",
    "print(longs)\n",
    "shorts = dict(m['is_short'].value_counts().items()).get(1)\n",
    "print(shorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed state 0/22899\n",
      "Current Predicted Reward: 0\n",
      "Current Actual Reward: -10.39031099\n",
      "Processed state 100/22899\n",
      "Current Predicted Reward: -5.940811860000018\n",
      "Current Actual Reward: -81.90489316999994\n",
      "Processed state 200/22899\n",
      "Current Predicted Reward: 26.133953569999985\n",
      "Current Actual Reward: -4.461696309999955\n",
      "Processed state 300/22899\n",
      "Current Predicted Reward: 78.09301181999997\n",
      "Current Actual Reward: 110.30025739\n",
      "Processed state 400/22899\n",
      "Current Predicted Reward: 124.36028403\n",
      "Current Actual Reward: 214.67899305000003\n",
      "Processed state 500/22899\n",
      "Current Predicted Reward: 161.24423028000007\n",
      "Current Actual Reward: 363.77701687999996\n",
      "Processed state 600/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 471.99834889999977\n",
      "Processed state 700/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 570.2997075199997\n",
      "Processed state 800/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 637.4957714699999\n",
      "Processed state 900/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 695.62739606\n",
      "Processed state 1000/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 792.4393774100005\n",
      "Processed state 1100/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 879.2184595300005\n",
      "Processed state 1200/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 1041.58390391\n",
      "Processed state 1300/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 1151.4030746899994\n",
      "Processed state 1400/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 1308.1557709899998\n",
      "Processed state 1500/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 1396.7334484400003\n",
      "Processed state 1600/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 1534.5798843400005\n",
      "Processed state 1700/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 1598.372620270001\n",
      "Processed state 1800/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 1653.0295273900026\n",
      "Processed state 1900/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 1724.7969678400018\n",
      "Processed state 2000/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 1821.6023596300015\n",
      "Processed state 2100/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 1900.7122174200003\n",
      "Processed state 2200/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 1984.1215909699995\n",
      "Processed state 2300/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 2067.6357071800003\n",
      "Processed state 2400/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 2159.68708223\n",
      "Processed state 2500/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 2233.503833669999\n",
      "Processed state 2600/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 2317.073714149999\n",
      "Processed state 2700/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 2445.562074049999\n",
      "Processed state 2800/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 2537.48825332\n",
      "Processed state 2900/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 2648.12030767\n",
      "Processed state 3000/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 2774.9528054499992\n",
      "Processed state 3100/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 2830.93775001\n",
      "Processed state 3200/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 2901.8431385100016\n",
      "Processed state 3300/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 2997.855574570003\n",
      "Processed state 3400/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 3144.752176100002\n",
      "Processed state 3500/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 3277.669070410002\n",
      "Processed state 3600/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 3386.1147913600016\n",
      "Processed state 3700/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 3517.742525620001\n",
      "Processed state 3800/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 3599.350870100002\n",
      "Processed state 3900/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 3678.145861030001\n",
      "Processed state 4000/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 3788.059950990001\n",
      "Processed state 4100/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 3877.10157793\n",
      "Processed state 4200/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 3967.793021269998\n",
      "Processed state 4300/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 4024.459989019995\n",
      "Processed state 4400/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 4096.419247309995\n",
      "Processed state 4500/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 4198.342792249991\n",
      "Processed state 4600/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 4297.321301859992\n",
      "Processed state 4700/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 4385.063990819987\n",
      "Processed state 4800/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 4483.834634759988\n",
      "Processed state 4900/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 4658.229808939991\n",
      "Processed state 5000/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 4741.830495639989\n",
      "Processed state 5100/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 4828.124403719984\n",
      "Processed state 5200/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 4892.730245539985\n",
      "Processed state 5300/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 5030.118325889986\n",
      "Processed state 5400/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 5123.556735719986\n",
      "Processed state 5500/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 5226.395809989987\n",
      "Processed state 5600/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 5318.224821799984\n",
      "Processed state 5700/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 5405.637970659986\n",
      "Processed state 5800/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 5571.567947839989\n",
      "Processed state 5900/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 5694.4156559599905\n",
      "Processed state 6000/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 5806.555927389988\n",
      "Processed state 6100/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 5925.0108526099875\n",
      "Processed state 6200/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 6019.687641579988\n",
      "Processed state 6300/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 6115.307262039989\n",
      "Processed state 6400/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 6226.141644299988\n",
      "Processed state 6500/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 6327.695120329987\n",
      "Processed state 6600/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 6415.894830029983\n",
      "Processed state 6700/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 6540.34610588998\n",
      "Processed state 6800/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 6671.309282719984\n",
      "Processed state 6900/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 6771.880631369985\n",
      "Processed state 7000/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 6881.164678089988\n",
      "Processed state 7100/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 7026.051390459987\n",
      "Processed state 7200/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 7184.56560935998\n",
      "Processed state 7300/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 7312.13989434998\n",
      "Processed state 7400/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 7439.585381099978\n",
      "Processed state 7500/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 7571.358641609978\n",
      "Processed state 7600/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 7691.91905675998\n",
      "Processed state 7700/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 7797.43163434998\n",
      "Processed state 7800/22899\n",
      "Current Predicted Reward: 183.1689004600001\n",
      "Current Actual Reward: 7956.168603939984\n",
      "Processed state 7900/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 8099.668914639982\n",
      "Processed state 8000/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 8252.282403719984\n",
      "Processed state 8100/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 8349.986677889983\n",
      "Processed state 8200/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 8474.14465822998\n",
      "Processed state 8300/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 8639.438004319984\n",
      "Processed state 8400/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 8782.808391649984\n",
      "Processed state 8500/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 8873.942496379987\n",
      "Processed state 8600/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 8973.062750759986\n",
      "Processed state 8700/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 9076.625343249985\n",
      "Processed state 8800/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 9177.761007359975\n",
      "Processed state 8900/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 9266.204703529975\n",
      "Processed state 9000/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 9334.31876781998\n",
      "Processed state 9100/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 9440.463339979982\n",
      "Processed state 9200/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 9527.026796519978\n",
      "Processed state 9300/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 9641.055508529973\n",
      "Processed state 9400/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 9776.643582399967\n",
      "Processed state 9500/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 9853.518636189967\n",
      "Processed state 9600/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 9938.48202026998\n",
      "Processed state 9700/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 10003.235451849985\n",
      "Processed state 9800/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 10086.188850649987\n",
      "Processed state 9900/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 10187.165526719995\n",
      "Processed state 10000/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 10257.240875169993\n",
      "Processed state 10100/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 10324.512911409987\n",
      "Processed state 10200/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 10423.258591189984\n",
      "Processed state 10300/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 10523.25740134998\n",
      "Processed state 10400/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 10617.222293989978\n",
      "Processed state 10500/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 10730.67217813998\n",
      "Processed state 10600/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 10808.987619259975\n",
      "Processed state 10700/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 10906.238093739978\n",
      "Processed state 10800/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 11000.512348399967\n",
      "Processed state 10900/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 11128.783970509972\n",
      "Processed state 11000/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 11208.191918529965\n",
      "Processed state 11100/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 11288.152613239969\n",
      "Processed state 11200/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 11389.285306879976\n",
      "Processed state 11300/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 11484.196128769963\n",
      "Processed state 11400/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 11602.675768849966\n",
      "Processed state 11500/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 11667.58999319997\n",
      "Processed state 11600/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 11755.453787909972\n",
      "Processed state 11700/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 11824.223123709973\n",
      "Processed state 11800/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 11904.529550949976\n",
      "Processed state 11900/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 11988.890354249968\n",
      "Processed state 12000/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 12071.899658869968\n",
      "Processed state 12100/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 12205.216334529972\n",
      "Processed state 12200/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 12286.468520239972\n",
      "Processed state 12300/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 12362.69611665998\n",
      "Processed state 12400/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 12439.829830979981\n",
      "Processed state 12500/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 12529.394290559985\n",
      "Processed state 12600/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 12618.865874649993\n",
      "Processed state 12700/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 12705.556684979992\n",
      "Processed state 12800/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 12794.217594519994\n",
      "Processed state 12900/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 12872.097415490001\n",
      "Processed state 13000/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 12947.547719569999\n",
      "Processed state 13100/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 13066.025672309994\n",
      "Processed state 13200/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 13159.418955139992\n",
      "Processed state 13300/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 13258.761811449996\n",
      "Processed state 13400/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 13341.771214199987\n",
      "Processed state 13500/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 13415.756617499994\n",
      "Processed state 13600/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 13484.741895549989\n",
      "Processed state 13700/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 13537.150073269988\n",
      "Processed state 13800/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 13593.537243849982\n",
      "Processed state 13900/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 13669.99868239998\n",
      "Processed state 14000/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 13754.748059459987\n",
      "Processed state 14100/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 13864.343574789984\n",
      "Processed state 14200/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 13953.533351999995\n",
      "Processed state 14300/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 14137.083413609991\n",
      "Processed state 14400/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 14242.218593919997\n",
      "Processed state 14500/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 14311.771203519995\n",
      "Processed state 14600/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 14414.416705589987\n",
      "Processed state 14700/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 14501.474735249985\n",
      "Processed state 14800/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 14612.38590819999\n",
      "Processed state 14900/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 14725.564637989992\n",
      "Processed state 15000/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 14835.53220228999\n",
      "Processed state 15100/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 14930.399309339999\n",
      "Processed state 15200/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 14997.53251766999\n",
      "Processed state 15300/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 15065.84646246999\n",
      "Processed state 15400/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 15144.762568379989\n",
      "Processed state 15500/22899\n",
      "Current Predicted Reward: 204.48711069000007\n",
      "Current Actual Reward: 15304.681079249978\n",
      "Processed state 15600/22899\n",
      "Current Predicted Reward: 210.10858530000007\n",
      "Current Actual Reward: 15424.508539579982\n",
      "Processed state 15700/22899\n",
      "Current Predicted Reward: 274.0603891399999\n",
      "Current Actual Reward: 15526.225183289976\n",
      "Processed state 15800/22899\n",
      "Current Predicted Reward: 274.0603891399999\n",
      "Current Actual Reward: 15640.212959479983\n",
      "Processed state 15900/22899\n",
      "Current Predicted Reward: 274.0603891399999\n",
      "Current Actual Reward: 15733.945079589977\n",
      "Processed state 16000/22899\n",
      "Current Predicted Reward: 274.98510983999995\n",
      "Current Actual Reward: 15833.08312375997\n",
      "Processed state 16100/22899\n",
      "Current Predicted Reward: 274.98510983999995\n",
      "Current Actual Reward: 15955.984147279969\n",
      "Processed state 16200/22899\n",
      "Current Predicted Reward: 362.0592736099997\n",
      "Current Actual Reward: 16078.337906159973\n",
      "Processed state 16300/22899\n",
      "Current Predicted Reward: 482.8325651499999\n",
      "Current Actual Reward: 16208.613642229979\n",
      "Processed state 16400/22899\n",
      "Current Predicted Reward: 482.8325651499999\n",
      "Current Actual Reward: 16289.924421989985\n",
      "Processed state 16500/22899\n",
      "Current Predicted Reward: 524.8586616599998\n",
      "Current Actual Reward: 16383.422688669976\n",
      "Processed state 16600/22899\n",
      "Current Predicted Reward: 624.9998484299999\n",
      "Current Actual Reward: 16483.563875439988\n",
      "Processed state 16700/22899\n",
      "Current Predicted Reward: 710.4635207000001\n",
      "Current Actual Reward: 16569.027547709993\n",
      "Processed state 16800/22899\n",
      "Current Predicted Reward: 772.6907864800002\n",
      "Current Actual Reward: 16631.254813489984\n",
      "Processed state 16900/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 16700.947513369985\n",
      "Processed state 17000/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 16774.747922259983\n",
      "Processed state 17100/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 16862.245556709975\n",
      "Processed state 17200/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 16959.754319589974\n",
      "Processed state 17300/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 17043.332072949957\n",
      "Processed state 17400/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 17101.29713256995\n",
      "Processed state 17500/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 17179.582563979944\n",
      "Processed state 17600/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 17247.009137689944\n",
      "Processed state 17700/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 17333.867032299946\n",
      "Processed state 17800/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 17426.70390686994\n",
      "Processed state 17900/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 17527.017386369946\n",
      "Processed state 18000/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 17602.970205289927\n",
      "Processed state 18100/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 17710.262149179936\n",
      "Processed state 18200/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 17795.74580788994\n",
      "Processed state 18300/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 17874.459496739946\n",
      "Processed state 18400/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 17954.841832439957\n",
      "Processed state 18500/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 18083.08579876995\n",
      "Processed state 18600/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 18197.94486708995\n",
      "Processed state 18700/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 18261.709794789953\n",
      "Processed state 18800/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 18363.123436389953\n",
      "Processed state 18900/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 18499.25197252996\n",
      "Processed state 19000/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 18619.78032710996\n",
      "Processed state 19100/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 18723.489835109947\n",
      "Processed state 19200/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 18828.822764759945\n",
      "Processed state 19300/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 18943.90035163993\n",
      "Processed state 19400/22899\n",
      "Current Predicted Reward: 774.24224674\n",
      "Current Actual Reward: 19044.55369396994\n",
      "Processed state 19500/22899\n",
      "Current Predicted Reward: 819.9947942499997\n",
      "Current Actual Reward: 19105.173930189954\n",
      "Processed state 19600/22899\n",
      "Current Predicted Reward: 915.5862588999996\n",
      "Current Actual Reward: 19203.992849859962\n",
      "Processed state 19700/22899\n",
      "Current Predicted Reward: 1060.1653274100001\n",
      "Current Actual Reward: 19350.96688388995\n",
      "Processed state 19800/22899\n",
      "Current Predicted Reward: 1096.3001226499998\n",
      "Current Actual Reward: 19446.910935889973\n",
      "Processed state 19900/22899\n",
      "Current Predicted Reward: 1096.3001226499998\n",
      "Current Actual Reward: 19541.95860466998\n",
      "Processed state 20000/22899\n",
      "Current Predicted Reward: 1112.8326833099998\n",
      "Current Actual Reward: 19659.752699309985\n",
      "Processed state 20100/22899\n",
      "Current Predicted Reward: 1113.3604719599998\n",
      "Current Actual Reward: 19818.578203539986\n",
      "Processed state 20200/22899\n",
      "Current Predicted Reward: 1113.3604719599998\n",
      "Current Actual Reward: 19891.122407259983\n",
      "Processed state 20300/22899\n",
      "Current Predicted Reward: 1113.3604719599998\n",
      "Current Actual Reward: 19981.669158269997\n",
      "Processed state 20400/22899\n",
      "Current Predicted Reward: 1113.3604719599998\n",
      "Current Actual Reward: 20066.622775040003\n",
      "Processed state 20500/22899\n",
      "Current Predicted Reward: 1135.05598662\n",
      "Current Actual Reward: 20147.667303879985\n",
      "Processed state 20600/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 20271.217536039996\n",
      "Processed state 20700/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 20367.400430700003\n",
      "Processed state 20800/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 20467.01446086002\n",
      "Processed state 20900/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 20540.390066880016\n",
      "Processed state 21000/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 20679.988097890015\n",
      "Processed state 21100/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 20765.635198090007\n",
      "Processed state 21200/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 20861.443863260007\n",
      "Processed state 21300/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 21009.044626920007\n",
      "Processed state 21400/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 21098.18182647\n",
      "Processed state 21500/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 21208.37230316001\n",
      "Processed state 21600/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 21296.47309595999\n",
      "Processed state 21700/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 21415.28326297\n",
      "Processed state 21800/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 21521.247188459998\n",
      "Processed state 21900/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 21606.992860389993\n",
      "Processed state 22000/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 20934.75751559001\n",
      "Processed state 22100/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 18605.22106048001\n",
      "Processed state 22200/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 16282.763332920022\n",
      "Processed state 22300/22899\n",
      "Current Predicted Reward: 1238.8125250700002\n",
      "Current Actual Reward: 13925.448045290012\n",
      "Processed state 22400/22899\n",
      "Current Predicted Reward: 948.9392502000001\n",
      "Current Actual Reward: 11534.18148028001\n",
      "Processed state 22500/22899\n",
      "Current Predicted Reward: 617.8449536900001\n",
      "Current Actual Reward: 9189.03086853001\n",
      "Processed state 22600/22899\n",
      "Current Predicted Reward: 278.9423453400001\n",
      "Current Actual Reward: 6768.662787210007\n",
      "Processed state 22700/22899\n",
      "Current Predicted Reward: 278.9423453400001\n",
      "Current Actual Reward: 4352.82627804001\n",
      "Processed state 22800/22899\n",
      "Current Predicted Reward: 278.9423453400001\n",
      "Current Actual Reward: 1960.60263143001\n",
      "Cumulative Predicted Reward: -42.00502896999993\n",
      "Cumulative Actual Reward: -407.70252593998924\n",
      "Prediction Efficiency: 89.70%\n"
     ]
    }
   ],
   "source": [
    "# Performance measures\n",
    "# Initialize cumulative rewards\n",
    "cumulative_predicted_reward = 0\n",
    "cumulative_actual_reward = 0\n",
    "#n_states = states.shape[0]\n",
    "#q_table = loaded_qtable\n",
    "# Iterate through states to calculate rewards\n",
    "for state_index in range(n_states - 1):\n",
    "    # Predicted action from Q-table\n",
    "    predicted_action = np.argmax(q_table[state_index])  # Best action for the current state\n",
    "    # Actual action from the ground truth\n",
    "    actual_action = train_data[\"action_num\"].iloc[state_index]\n",
    "\n",
    "    # Get reward for predicted action only if it matches the actual action\n",
    "    if predicted_action == actual_action:\n",
    "        predicted_reward = rewards[state_index + 1]  # Reward for the correct prediction\n",
    "        cumulative_predicted_reward += predicted_reward\n",
    "\n",
    "    # Get actual reward for the ground truth action\n",
    "    actual_reward = rewards[state_index + 1]\n",
    "    cumulative_actual_reward += actual_reward\n",
    "\n",
    "    # Optional: Log progress\n",
    "    if state_index % 100 == 0:  # Adjust logging frequency as needed\n",
    "        print(f\"Processed state {state_index}/{n_states - 1}\")\n",
    "        print(f\"Current Predicted Reward: {cumulative_predicted_reward}\")\n",
    "        print(f\"Current Actual Reward: {cumulative_actual_reward}\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Cumulative Predicted Reward: {cumulative_predicted_reward}\")\n",
    "print(f\"Cumulative Actual Reward: {cumulative_actual_reward}\")\n",
    "\n",
    "# Optionally calculate efficiency\n",
    "efficiency = (\n",
    "    ((cumulative_predicted_reward - cumulative_actual_reward) / abs(cumulative_actual_reward)) * 100\n",
    "    if cumulative_actual_reward != 0\n",
    "    else 0\n",
    ")\n",
    "print(f\"Prediction Efficiency: {efficiency:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 5.49%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "correct_predictions = 0\n",
    "for state_index in range(n_states):\n",
    "    predicted_action = np.argmax(q_table[state_index])  # Predicted action\n",
    "    actual_action = train_data[\"action_num\"].iloc[state_index]  # Actual action\n",
    "    if predicted_action == actual_action:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / n_states\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 1059     1     1]\n",
      " [21507   199   133]\n",
      " [    0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "y_true = train_data[\"action_num\"]  # Actual actions\n",
    "y_pred = [np.argmax(q_table[state_index]) for state_index in range(n_states)]  # Predicted actions\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_accuracy(conf_matrix, n_states):\n",
    "    # True Positives (TP): Diagonal elements of the confusion matrix\n",
    "    TP = conf_matrix[0][0] + conf_matrix[1][1] + conf_matrix[2][2]\n",
    "    # **True Positives**: 16 (class 0), 0 (class 1), 0 (class 2)\n",
    "    return TP*100/n_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con_acc = confusion_accuracy(cm, n_states=n_states)\n",
    "#print(f\"confusion accuracy: {con_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_short\n",
       "1    21897\n",
       "0     1003\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['is_short'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_reward(action: str, is_short: int):\n",
    "    m = train_data[(train_data['predicted_action'] == f'{action}') & (train_data['is_short'] == is_short)]\n",
    "    counts = m['is_short'].value_counts()\n",
    "    total_reward = m['reward'].cumsum()[-1:].values[0]\n",
    "    wins = len(m[m['reward'] > 0])\n",
    "    losses = len(m[m['reward'] <= 0])\n",
    "    return {\n",
    "        'counts': counts.get(is_short),\n",
    "        'total reward': total_reward,\n",
    "        'winrate': f'{wins * 100 / (losses + wins):.2f}%',\n",
    "        'per trade profit': m[m['reward'] > 0]['reward'].sum() / wins,\n",
    "        'per trade loss': m[m['reward'] <= 0]['reward'].sum() / losses\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'counts': 1002,\n",
       " 'total reward': -44.0996075499998,\n",
       " 'winrate': '93.71%',\n",
       " 'per trade profit': 1.137017633312034,\n",
       " 'per trade loss': -17.646970876666664}"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_reward('go_long', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go_long 0: {'counts': 1002, 'total reward': -44.0996075499998, 'winrate': '93.71%', 'per trade profit': 1.137017633312034, 'per trade loss': -17.646970876666664}\n",
      "go_long 1: {'counts': 21564, 'total reward': -628.0213629899955, 'winrate': '95.03%', 'per trade profit': 0.9995474176172352, 'per trade loss': -19.712181692082165}\n",
      "go_short 0: {'counts': 1, 'total reward': -3.60169813, 'winrate': '0.00%', 'per trade profit': nan, 'per trade loss': -3.60169813}\n",
      "go_short 1: {'counts': 199, 'total reward': 114.64950858000007, 'winrate': '95.98%', 'per trade profit': 1.0214986905235603, 'per trade loss': -10.057092663750002}\n",
      "index 0 is out of bounds for axis 0 with size 0\n",
      "do_nothing 1: {'counts': 134, 'total reward': 141.91113903000007, 'winrate': '97.76%', 'per trade profit': 1.2791417797709923, 'per trade loss': -8.552144706666667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3167762/3005952004.py:11: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  'per trade profit': m[m['reward'] > 0]['reward'].sum() / wins,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dirs = [0,1]\n",
    "for action in action_mapping.keys():\n",
    "    for is_short in dirs:\n",
    "        try:\n",
    "            print(f'{action} {is_short}: {action_reward(action, is_short)}')\n",
    "        except IndexError as e:\n",
    "            print(e)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list of rewards for each episode\n",
    "#rewards_per_episode = [...]  # Populate this with your actual data\n",
    "\n",
    "plt.plot(rewards_per_episode)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Rewards per Episode')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create corrected action\n",
    "def correct_action(row):\n",
    "    if row['predicted_action'] == 'go_long' and row['is_short'] == 1 and row['reward'] > 0:\n",
    "        return 'go_short'\n",
    "    if row['predicted_action'] == 'go_short' and row['is_short'] == 0 and row['reward'] > 0:\n",
    "        return 'go_long'\n",
    "    if row['predicted_action'] == 'do_nothing' and row['is_short'] == 1 and row['reward'] > 0:\n",
    "        return 'go_short'\n",
    "    if row['predicted_action'] == 'do_nothing' and row['is_short'] == 0 and row['reward'] > 0:\n",
    "        return 'go_long'\n",
    "    return row['predicted_action']\n",
    "\n",
    "def refiner_action(version: str, data: DataFrame = None) -> DataFrame:\n",
    "    data['refined-action'] = data.apply(lambda x: correct_action(x), axis=1)\n",
    "    # Validation: Ensure we're fixing the 751 misclassified entries\n",
    "    misclassified = data[\n",
    "        (data['predicted_action'] == 'go_long') & \n",
    "        (data['refined-action'] == 'go_short')\n",
    "    ]\n",
    "    # Add this after applying refined-action\n",
    "    confusion_matrix = pd.crosstab(\n",
    "        data['refined-action'], \n",
    "        data['predicted_action'],  # Assuming you have ground truth column\n",
    "        rownames=['refined'],\n",
    "        colnames=['predicted']\n",
    "    )\n",
    "    print(\"Updated Confusion Matrix:\")\n",
    "    print(confusion_matrix) \n",
    "    print(f\"Corrected {len(misclassified)} go_long->go_short misclassifications\")\n",
    "    filename = f'../spreadsheets/rlhf_bid_{version}_refined.csv'\n",
    "    data.to_csv(filename, index=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/defi/Desktop/portfolio/projects/python/pipeline_defi/'\n",
    "#new_data = pd.read_csv('../spreadsheets/rlhf_small_154nlp.csv') \n",
    "def refine_file(version: str, file) -> DataFrame:\n",
    "    filename = f'{base_dir}{file}.csv'\n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename)\n",
    "    #new_data = prep_data(df0.copy()) if newdf0.empty else prep_data(newdf0.copy())\n",
    "    new_data = prep_data(df)   \n",
    "    print(new_data.columns)\n",
    "    new_train_data = refiner_action(version=version, data=new_data)\n",
    "\n",
    "    #new_data = df0.copy()\n",
    "    print(new_train_data.columns)\n",
    "\n",
    "    new_train_data['nlpreds'] = new_train_data['predicted_action']\n",
    "    #new_train_data['predicted_action'] = new_train_data['predicted_action']\n",
    "    return new_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/defi/Desktop/portfolio/projects/python/pipeline_defi/lean_df_154nlp.csv\n",
      "Index(['open', 'high', 'ema-26', 'ema-12', 'low', 'mean-grad-hist', 'close',\n",
      "       'volume', 'sma-25', 'long_jcrosk', 'short_kdj', 'sma-compare', 'ask',\n",
      "       'bid', 'is_short', 'predicted_action', 'reward'],\n",
      "      dtype='object')\n",
      "Updated Confusion Matrix:\n",
      "predicted   do_nothing  go_long  go_short\n",
      "refined                                  \n",
      "do_nothing          12        0         0\n",
      "go_long              1      356         0\n",
      "go_short             1      197         4\n",
      "Corrected 197 go_long->go_short misclassifications\n",
      "Index(['open', 'high', 'ema-26', 'ema-12', 'low', 'mean-grad-hist', 'close',\n",
      "       'volume', 'sma-25', 'long_jcrosk', 'short_kdj', 'sma-compare', 'ask',\n",
      "       'bid', 'is_short', 'predicted_action', 'reward', 'refined-action'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "newdf0 = refine_file('154nlp', 'lean_df_154nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef train_q_learning(alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes, n_states, n_actions, rewards):\\n    q_table = np.zeros((n_states, n_actions))\\n    rewards_per_episode = []\\n\\n    for episode in range(n_episodes):\\n        current_state = np.random.randint(0, n_states)\\n        total_reward = 0\\n\\n        while current_state < n_states - 1:\\n            if np.random.uniform(0, 1) < epsilon:\\n                action = np.random.randint(0, n_actions)\\n            else:\\n                action = np.argmax(q_table[current_state])\\n\\n            next_state = current_state + 1  # Adjust based on environment logic\\n            reward = rewards[next_state]\\n\\n            best_next_action = np.argmax(q_table[next_state])\\n            q_table[current_state, action] += alpha * (\\n                reward + gamma * q_table[next_state, best_next_action] - q_table[current_state, action]\\n            )\\n\\n            total_reward += reward\\n            current_state = next_state\\n\\n        rewards_per_episode.append(total_reward)\\n        epsilon = max(min_epsilon, epsilon * decay_rate) # default min_epsilon = 0.01\\n\\n    return q_table, rewards_per_episode\\n'"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuning\n",
    "'''\n",
    "def train_q_learning(alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes, n_states, n_actions, rewards):\n",
    "    q_table = np.zeros((n_states, n_actions))\n",
    "    rewards_per_episode = []\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        current_state = np.random.randint(0, n_states)\n",
    "        total_reward = 0\n",
    "\n",
    "        while current_state < n_states - 1:\n",
    "            if np.random.uniform(0, 1) < epsilon:\n",
    "                action = np.random.randint(0, n_actions)\n",
    "            else:\n",
    "                action = np.argmax(q_table[current_state])\n",
    "\n",
    "            next_state = current_state + 1  # Adjust based on environment logic\n",
    "            reward = rewards[next_state]\n",
    "\n",
    "            best_next_action = np.argmax(q_table[next_state])\n",
    "            q_table[current_state, action] += alpha * (\n",
    "                reward + gamma * q_table[next_state, best_next_action] - q_table[current_state, action]\n",
    "            )\n",
    "\n",
    "            total_reward += reward\n",
    "            current_state = next_state\n",
    "\n",
    "        rewards_per_episode.append(total_reward)\n",
    "        epsilon = max(min_epsilon, epsilon * decay_rate) # default min_epsilon = 0.01\n",
    "\n",
    "    return q_table, rewards_per_episode\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_q_learning_reward_weighted(q_table, n_states, train_data, rewards):\n",
    "    correct_predictions = 0\n",
    "    total_reward = 0\n",
    "    reward_weighted_accuracy = []\n",
    "\n",
    "    # Add tqdm for progress visualization\n",
    "    for state_index in tqdm(range(n_states), desc=\"Evaluating States\"):\n",
    "        predicted_action = np.argmax(q_table[state_index])  # Predicted action\n",
    "        actual_action = train_data[\"action_num\"].iloc[state_index]  # Actual action\n",
    "        reward = rewards[state_index]  # Reward for the action\n",
    "\n",
    "        if predicted_action == actual_action:\n",
    "            correct_predictions += 1\n",
    "            total_reward += reward\n",
    "\n",
    "        accuracy = correct_predictions / (state_index + 1)\n",
    "        reward_weighted_accuracy.append(total_reward / (state_index + 1))\n",
    "\n",
    "        # Optional: Log progress\n",
    "        if state_index % 100 == 0:\n",
    "            print(f\"Processed state {state_index}/{n_states} - Accuracy: {accuracy * 100:.2f}%, Reward-weighted Accuracy: {reward_weighted_accuracy[-1]}\")\n",
    "\n",
    "    final_reward_weighted_accuracy = total_reward / n_states\n",
    "    return final_reward_weighted_accuracy * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef random_search_reward_weighted(n_iter, param_grid, n_states, n_actions, rewards, train_data):\\n    best_params = None\\n    best_reward_weighted_accuracy = float(\\'-inf\\')\\n\\n    for _ in tqdm(range(n_iter), desc=\"Searching for params ...\"):\\n        alpha = random.choice(param_grid[\\'alpha\\'])\\n        gamma = random.choice(param_grid[\\'gamma\\'])\\n        epsilon = random.choice(param_grid[\\'epsilon\\'])\\n        min_epsilon = random.choice(param_grid[\\'decay_rate\\'])\\n        decay_rate = random.choice(param_grid[\\'decay_rate\\'])\\n        n_episodes = random.choice(param_grid[\\'n_episodes\\'])\\n\\n        q_table, _ = train_q_learning(alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes, n_states, n_actions, rewards)\\n        reward_weighted_accuracy = evaluate_q_learning_reward_weighted(q_table, n_states, train_data, rewards)\\n\\n        if reward_weighted_accuracy > best_reward_weighted_accuracy:\\n            best_reward_weighted_accuracy = reward_weighted_accuracy\\n            best_params = (alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes)\\n\\n        print(f\"Iteration Reward-weighted Accuracy: {reward_weighted_accuracy:.2f}%, Best Reward-weighted Accuracy: {best_reward_weighted_accuracy:.2f}%\")\\n\\n    return best_params, best_reward_weighted_accuracy\\n\\n# Define the parameter grid\\nparam_grid = {\\n    \\'alpha\\': [0.01, 0.05, 0.1, 0.2, 0.25, 0.3, 0.5, 0.7, 0.9, 1],\\n    \\'gamma\\': [0.75, 0.85, 0.9, 0.95, 0.99],\\n    \\'epsilon\\': [1.0, 0.5, 0.1, 0.05, 0.01, 0.005],\\n    \\'min_epsilon\\': [0.05, 0.01, 0.005, 0.001, 0.001],\\n    \\'decay_rate\\': [0.95, 0.99, 0.995, 0.997, 0.999],\\n    \\'n_episodes\\': [1500, 4000,6000, 8000, 9000, 10000, 11000, 12000]\\n}\\n\\n# Perform Random Search\\nbest_params, best_reward_weighted_accuracy = random_search_reward_weighted(50, param_grid, n_states, n_actions, rewards, train_data)\\nprint(f\"Best Hyperparameters: {best_params}\")\\nprint(f\"Best Reward-weighted Accuracy: {best_reward_weighted_accuracy:.2f}%\")\\n\\n'"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def random_search_reward_weighted(n_iter, param_grid, n_states, n_actions, rewards, train_data):\n",
    "    best_params = None\n",
    "    best_reward_weighted_accuracy = float('-inf')\n",
    "\n",
    "    for _ in tqdm(range(n_iter), desc=\"Searching for params ...\"):\n",
    "        alpha = random.choice(param_grid['alpha'])\n",
    "        gamma = random.choice(param_grid['gamma'])\n",
    "        epsilon = random.choice(param_grid['epsilon'])\n",
    "        min_epsilon = random.choice(param_grid['decay_rate'])\n",
    "        decay_rate = random.choice(param_grid['decay_rate'])\n",
    "        n_episodes = random.choice(param_grid['n_episodes'])\n",
    "\n",
    "        q_table, _ = train_q_learning(alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes, n_states, n_actions, rewards)\n",
    "        reward_weighted_accuracy = evaluate_q_learning_reward_weighted(q_table, n_states, train_data, rewards)\n",
    "\n",
    "        if reward_weighted_accuracy > best_reward_weighted_accuracy:\n",
    "            best_reward_weighted_accuracy = reward_weighted_accuracy\n",
    "            best_params = (alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes)\n",
    "\n",
    "        print(f\"Iteration Reward-weighted Accuracy: {reward_weighted_accuracy:.2f}%, Best Reward-weighted Accuracy: {best_reward_weighted_accuracy:.2f}%\")\n",
    "\n",
    "    return best_params, best_reward_weighted_accuracy\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.05, 0.1, 0.2, 0.25, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "    'gamma': [0.75, 0.85, 0.9, 0.95, 0.99],\n",
    "    'epsilon': [1.0, 0.5, 0.1, 0.05, 0.01, 0.005],\n",
    "    'min_epsilon': [0.05, 0.01, 0.005, 0.001, 0.001],\n",
    "    'decay_rate': [0.95, 0.99, 0.995, 0.997, 0.999],\n",
    "    'n_episodes': [1500, 4000,6000, 8000, 9000, 10000, 11000, 12000]\n",
    "}\n",
    "\n",
    "# Perform Random Search\n",
    "best_params, best_reward_weighted_accuracy = random_search_reward_weighted(50, param_grid, n_states, n_actions, rewards, train_data)\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Reward-weighted Accuracy: {best_reward_weighted_accuracy:.2f}%\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_q_learning_prediction_efficiency(q_table, n_states, train_data, rewards):\n",
    "    # Initialize cumulative rewards\n",
    "    cumulative_predicted_reward = 0\n",
    "    cumulative_actual_reward = 0\n",
    "\n",
    "    # Iterate through states to calculate rewards\n",
    "    for state_index in range(n_states - 1):\n",
    "        # Predicted action from Q-table\n",
    "        predicted_action = np.argmax(q_table[state_index])  # Best action for the current state\n",
    "        # Actual action from the ground truth\n",
    "        actual_action = train_data[\"action_num\"].iloc[state_index]\n",
    "\n",
    "        # Get reward for predicted action only if it matches the actual action\n",
    "        if predicted_action == actual_action:\n",
    "            predicted_reward = rewards[state_index + 1]  # Reward for the correct prediction\n",
    "            cumulative_predicted_reward += predicted_reward\n",
    "\n",
    "        # Get actual reward for the ground truth action\n",
    "        actual_reward = rewards[state_index + 1]\n",
    "        cumulative_actual_reward += actual_reward\n",
    "    return cumulative_predicted_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_data = newdf0\\ndef random_search_prediction_efficiency(n_iter, param_grid, n_states, n_actions, rewards, train_data):\\n    best_params = None\\n    best_cumulative_pred_reward = float(\\'-inf\\')\\n\\n    for _ in tqdm(range(n_iter), desc=\"Searching for params ...\"):\\n        alpha = random.choice(param_grid[\\'alpha\\'])\\n        gamma = random.choice(param_grid[\\'gamma\\'])\\n        epsilon = random.choice(param_grid[\\'epsilon\\'])\\n        min_epsilon = random.choice(param_grid[\\'decay_rate\\'])\\n        decay_rate = random.choice(param_grid[\\'decay_rate\\'])\\n        n_episodes = random.choice(param_grid[\\'n_episodes\\'])\\n\\n        q_table, _ = train_q_learning(alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes, n_states, n_actions, rewards)\\n        cumulative_pred_reward = evaluate_q_learning_prediction_efficiency(q_table, n_states, train_data, rewards)\\n\\n        if cumulative_pred_reward > best_cumulative_pred_reward:\\n            best_cumulative_pred_reward = cumulative_pred_reward\\n            best_params = (alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes)\\n\\n        print(f\"Iteration cumulative predicted reward: {cumulative_pred_reward:.2f}%, Best cumulative predicted reward: {best_cumulative_pred_reward:.2f}%\")\\n\\n    return best_params, best_cumulative_pred_reward\\n\\n# Define the parameter grid\\nparam_grid = {\\n    \\'alpha\\': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.25, 0.3, 0.5, 0.7, 0.9, 1],\\n    \\'gamma\\': [0.75, 0.85, 0.9, 0.95, 0.99],\\n    \\'epsilon\\': [1.0, 0.5, 0.1, 0.05, 0.01, 0.005],\\n    \\'min_epsilon\\': [0.05, 0.01, 0.005, 0.001, 0.001],\\n    \\'decay_rate\\': [0.95, 0.99, 0.995, 0.997, 0.999],\\n    \\'n_episodes\\': [1500, 4000,6000, 8000, 9000, 10000, 11000, 12000, 14000, 16000, 18000, 20000, 22000, 24000, 26000, 28000, 30000]\\n}\\n# 1500, 4000,6000, 8000, 9000, 10000, 11000, \\n# Perform Random Search\\nbest_params, best_cumulative_pred_reward = random_search_prediction_efficiency(50, param_grid, n_states, n_actions, rewards, train_data)\\nprint(f\"Best Hyperparameters: {best_params}\")\\nprint(f\"Best cumulative predicted reward: {best_cumulative_pred_reward:.2f}%\")\\n'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_data = newdf0\n",
    "def random_search_prediction_efficiency(n_iter, param_grid, n_states, n_actions, rewards, train_data):\n",
    "    best_params = None\n",
    "    best_cumulative_pred_reward = float('-inf')\n",
    "\n",
    "    for _ in tqdm(range(n_iter), desc=\"Searching for params ...\"):\n",
    "        alpha = random.choice(param_grid['alpha'])\n",
    "        gamma = random.choice(param_grid['gamma'])\n",
    "        epsilon = random.choice(param_grid['epsilon'])\n",
    "        min_epsilon = random.choice(param_grid['decay_rate'])\n",
    "        decay_rate = random.choice(param_grid['decay_rate'])\n",
    "        n_episodes = random.choice(param_grid['n_episodes'])\n",
    "\n",
    "        q_table, _ = train_q_learning(alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes, n_states, n_actions, rewards)\n",
    "        cumulative_pred_reward = evaluate_q_learning_prediction_efficiency(q_table, n_states, train_data, rewards)\n",
    "\n",
    "        if cumulative_pred_reward > best_cumulative_pred_reward:\n",
    "            best_cumulative_pred_reward = cumulative_pred_reward\n",
    "            best_params = (alpha, gamma, epsilon, min_epsilon, decay_rate, n_episodes)\n",
    "\n",
    "        print(f\"Iteration cumulative predicted reward: {cumulative_pred_reward:.2f}%, Best cumulative predicted reward: {best_cumulative_pred_reward:.2f}%\")\n",
    "\n",
    "    return best_params, best_cumulative_pred_reward\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.25, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "    'gamma': [0.75, 0.85, 0.9, 0.95, 0.99],\n",
    "    'epsilon': [1.0, 0.5, 0.1, 0.05, 0.01, 0.005],\n",
    "    'min_epsilon': [0.05, 0.01, 0.005, 0.001, 0.001],\n",
    "    'decay_rate': [0.95, 0.99, 0.995, 0.997, 0.999],\n",
    "    'n_episodes': [1500, 4000,6000, 8000, 9000, 10000, 11000, 12000, 14000, 16000, 18000, 20000, 22000, 24000, 26000, 28000, 30000]\n",
    "}\n",
    "# 1500, 4000,6000, 8000, 9000, 10000, 11000, \n",
    "# Perform Random Search\n",
    "best_params, best_cumulative_pred_reward = random_search_prediction_efficiency(50, param_grid, n_states, n_actions, rewards, train_data)\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best cumulative predicted reward: {best_cumulative_pred_reward:.2f}%\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsa = ['ask','bid','sma-compare','is_short','predicted_action','reward']\n",
    "learn_df = train_data[colsa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_action(action: str):\n",
    "    return ' '.join(action.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn_df.loc[:,['predicted_action']] = learn_df['predicted_action'] #.apply(split_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ask</th>\n",
       "      <th>bid</th>\n",
       "      <th>sma-compare</th>\n",
       "      <th>is_short</th>\n",
       "      <th>predicted_action</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.795012e+05</td>\n",
       "      <td>1.791188e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>go_long</td>\n",
       "      <td>-11.459495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.733907e+02</td>\n",
       "      <td>8.777623e+02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>go_long</td>\n",
       "      <td>-10.390311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.999426e+03</td>\n",
       "      <td>6.110315e+03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>go_long</td>\n",
       "      <td>-8.635224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.582064e+08</td>\n",
       "      <td>3.530371e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>go_long</td>\n",
       "      <td>-6.819206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.275311e+05</td>\n",
       "      <td>1.296819e+05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>go_short</td>\n",
       "      <td>-9.058079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ask           bid  sma-compare  is_short predicted_action  \\\n",
       "0  1.795012e+05  1.791188e+05            0         1          go_long   \n",
       "1  8.733907e+02  8.777623e+02            0         1          go_long   \n",
       "2  5.999426e+03  6.110315e+03            0         1          go_long   \n",
       "3  3.582064e+08  3.530371e+08            0         0          go_long   \n",
       "4  1.275311e+05  1.296819e+05            1         1         go_short   \n",
       "\n",
       "      reward  \n",
       "0 -11.459495  \n",
       "1 -10.390311  \n",
       "2  -8.635224  \n",
       "3  -6.819206  \n",
       "4  -9.058079  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn_df.to_csv('/home/defi/Desktop/portfolio/projects/python/pipeline_defi/lean_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
